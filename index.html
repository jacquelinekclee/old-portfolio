<!DOCTYPE HTML>
<!--
	Dimension by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>twas capstone project</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="logo">
							<div class="container">
								<span style="color: rgb(177, 136, 252)", class="icon fa-home"></span>
							</div>
						</div>
						<div class="content">
							<br>
							<p>
								<span class="center"><img src="images/tcg_headshot.jpg" alt="" width="500" height="500"/></span>
								<style>
								img {
								  display: block;
								  margin-left: auto;
								  margin-right: auto;
								}
								</style>
								<h1>Jacqueline Lee</h1>
								
							</p>
							<p style="color: rgba(255, 255, 255, 2.5); font-size:160%;">
								<i class="fa fa-envelope-open fa3x"></i> <a href="mailto:jacquelinekclee@yahoo.com"> E-Mail </a>

								<svg xmlns="http://www.w3.org/2000/svg" width="50" height="50" fill="currentColor" class="bi bi-linkedin" viewBox="0 0 16 16">
									<path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854V1.146zm4.943 12.248V6.169H2.542v7.225h2.401zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248-.822 0-1.359.54-1.359 1.248 0 .694.521 1.248 1.327 1.248h.016zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016a5.54 5.54 0 0 1 .016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225h2.4z"/>
								</svg> <a href="https://www.linkedin.com/in/jacqueline-kc-lee/">LinkedIn</a>

								<svg xmlns="http://www.w3.org/2000/svg" width="50" height="50" fill="currentColor" class="bi bi-github" viewBox="0 0 16 16">
									<path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"/>
								</svg> <a href="https://github.com/jacquelinekclee">GitHub</a>
							</p>
							<div class="inner">

								<p style="color: rgba(255, 255, 255, 2.5); font-size:150%;">
									Hello! I'm Jacqueline, a UC San Diego alum with a B.S. in Data Science and minors in Economics and Business. Welcome to my portfolio! 
									<br>Here, you'll find all of the Data Science projects I've done since I've started my Data Science journey back in 2019. 
									<br>Click on the links above to contact me.
								</p>
								<p style="color: rgba(255, 255, 255, 2.5); font-size:150%;">click the "Resume" box below to learn more about me any my experience</p>
								<nav class>
									<h2 style="color: rgba(255, 255, 255, 0.89)"> 
										<a style="border-width:3px; border-style:solid; border-color:rgb(177, 136, 252); padding: 1em; text-align:center" href="#resume"> <u>Resume</u> </a> 
									</h2>
								</nav>
								<br>
								<p style="color: rgba(255, 255, 255, 2.5); font-size:150%;">click on these boxes to look at the different projects i've done!</p>
								<nav class>
									<h2 style="color: rgba(255, 255, 255, 0.89)"> 
										<a style="border-width:3px; border-style:solid; border-color:rgb(177, 136, 252); padding: 1em; text-align:center" href="#positions"> <u>Random Forest/XGBoost: NBA Positions Classifier</u> </a> 
										<a style="border-width:3px; border-style:solid; border-color:rgb(177, 136, 252); padding: 1em; text-align:center" href="#hiphop"> <u>NLP/Webscraping: Has Hip Hop Gotten Worse?</u> </a> 
					
									</h2>
								</nav>
								<br>
								<br>
								<nav class>
									<h2 style="color: rgba(255, 255, 255, 0.89)"> 
										
										<a style="border-width:3px; border-style:solid; border-color:rgb(177, 136, 252); padding: 1em; text-align:center" href="#allstars"> <u>KNN: NBA All Stars Classifier</u> </a> 
										<a style="border-width:3px; border-style:solid; border-color:rgb(177, 136, 252); padding: 1em; text-align:center" href="https://jacquelinekclee.github.io/nba-data-viz-d3.github.io/"> <u>JavaScript/D3: NBA Data Viz</u> </a> 
										<a style="border-width:3px; border-style:solid; border-color:rgb(177, 136, 252); padding: 1em; text-align:center" href="#nypd"> <u>Ethics: Is the NYPD Fair?</u> </a> 
									</h2>
								</nav>
								
							</div>
						</div>

						
						
					</header>

				<!-- Main -->
					<div id="main">

						<!-- Intro -->
							<article id="resume">
                                
                                <h1 style = "text-align:center">Resume</h1>
								<iframe src="files/jacqueline_lee_resume_0123.pdf#toolbar=0" width="100%" height="2000px">
								</iframe>
								
							</article>

						<!-- Work -->
							<article id="nypd">
                                <h1 style = "text-align:center">Algorithmic Audit: Modeling the New York City Civilian Complaint Review Board and Auditing the Model Fairness</h1>

								<span class="center"><img src="images/Screen Shot 2022-09-08 at 5.37.33 PM-2.png" alt="" width="50%"/></span>
                            <style>
                                img {
                                  display: block;
                                  margin-left: auto;
                                  margin-right: auto;
                                }
                            </style>
							<h2>For full paper, <a href="https://github.com/jacquelinekclee/algorithmic-audit-nyc-ccrb/blob/aa536a7c4a71f71eaf114cd817be665e8a0b5252/paper2.pdf"> <u>click here</u> </a> </h2>
							<h2>For paper covering the background/investigation of inequity, <a href="https://github.com/jacquelinekclee/algorithmic-audit-nyc-ccrb/blob/08a597c91e40e83a4332684390dc4a4e5afbdf06/paper1.pdf"> <u>click here</u> </a> </h2>
   
							<p>
								Please note that this functions only as an overview of the work done! Please take a look at the final papers (linked above) or their corresponding Python notebooks:
								<ul>
									<li><a href="https://github.com/jacquelinekclee/algorithmic-audit-nyc-ccrb/blob/4120ace9bea5f2d2045f8d984f68f158b23f94f9/Paper%202%20-%20Modeling%20the%20New%20York%20City%20Civilian%20Complaint%20Review%20Board%20and%20Auditing%20the%20Model%20Fairness.ipynb"> <u>Algorithmic Audit Python Notebook Link</u> </a></li>
									<li><a href="https://github.com/jacquelinekclee/algorithmic-audit-nyc-ccrb/blob/4120ace9bea5f2d2045f8d984f68f158b23f94f9/Paper%201%20-%20Inequities%20in%20Civilian%20Complaints%20to%20the%20NYPD.ipynb"> <u>Inequities in Civilian Complaints to the NYPD Link</u> </a></li>
								</ul
							</p>		
							
							<h2>Background</h2>
							<p>This paper and analysis was done during Spring 2022 as part of the course <a href="https://afraenkel.github.io/fairness-algo-decision/"> <u>DSC 167</u> </a>: Fairness and Algorithmic Decision Making at UC San Diego's Halıcıoğlu Data Science Institute. 
								The purpose of the assignment and aim of this paper was to find a system or mechanism that has a potential inequity, model the decision making process, and evaluate/audit this model using parity measures and frameworks of distributive justice. 
								I hope that this paper can teach data scientists or those interested in the field about how ethics and fairness come into play in data science and the algorithms us data scientists create. 
							</p>
							<p>The New York City Civilian Complaint Review Board (CCRB), the system in this context, is an agency independent from the New York Police Department that investigates complaints against NYPD officers regarding allegations of excessive or unnecessary force, abuse of authority, discourtesy, or offensive language. 
								Throughout the investigation process, the review board may obtain further evidence from the NYPD (e.g., body camera footage) and conduct interviews of anyone involved to use alongside any details the complainant submitted in their original complaint. 
								Specific complainant/victim attributes collected include age, gender, and ethnicity. The complainant may also provide details on the officers's sex, race, and physical appearance.
							</p>
							<p>The potential inequity I investigated involves the "disposition" of a given complaint, or the ruling the CCRB determines. 
								A substantiated complaint is one for which the alleged conduct was found to have happened and violated NYPD rules, potentially leading to punishment or repercussions for the accused officer.
								 The data shows that complaints submitted by Black complainants were less often substantiated than non-Black complainants. 
								 This discrepancy was the launching pad for my investigation of this inequity and audit of the CCRB. 
							</p>

							<h2>Tools Used</h2>

							<span class="center"><img src="images/tools_used_pic.png" alt="" width="50%"/></span>
                            <style>
                                img {
                                  display: block;
                                  margin-left: auto;
                                  margin-right: auto;
                                }
                            </style>

							<ul>
								<li>Python</li>
								<li>Jupyter Notebooks</li>
								<li>Scikit Learn for Modeling</li>
								<li>Pandas for Data Cleaning, Exploration, etc.</li>
								<li>NumPy for Data Cleaning, Exploration, etc.</li>
								<li>Matplotlib for Data Visualization</li>
							</ul>

							<h2>The Data</h2>
							<p>
								The data originally comes from <a href="https://www.propublica.org/datastore/dataset/civilian-complaints-against-new-york-city-police-officers">ProPublica</a> and contains information regarding complaints made starting in 1985 up to 2020. 
								The model uses data starting in 2000 because key demographic features like complainant ethnicity were not tracked before then. 
								All complaints include the type of complaint made, the precinct in which the alleged action took place, demographics on the complainant, and demographics on the accused officer. 
								See <a href="https://github.com/jacquelinekclee/algorithmic-audit-nyc-ccrb/blob/ca06036fecf6efa016e9cd8de1fe9637768bffa5/allegations.csv">allegations.csv</a> and <a href="https://github.com/jacquelinekclee/algorithmic-audit-nyc-ccrb/blob/ca06036fecf6efa016e9cd8de1fe9637768bffa5/allegations_cleaned.csv">allegations_cleaned.csv</a>.
							</p>

							<h3>Additional Data</h3>
							<p>
								Borough was not a column initially included in the dataset, so the precincts were mapped to their apporpriate boroughs using data pulled from the <a href="https://www1.nyc.gov/site/nypd/bureaus/patrol/precincts-landing.page">NYPD's website</a>.
								See <a href="https://github.com/jacquelinekclee/algorithmic-audit-nyc-ccrb/blob/ca06036fecf6efa016e9cd8de1fe9637768bffa5/precinct_borough.csv">precinct_boroughs.csv</a>.
								In order to understand the different categories of complaints and the potential consequences an officer may face, I referenced the <a href = "https://www1.nyc.gov/assets/ccrb/downloads/pdf/about_pdf/Title38-A_20210526.pdf">CCRB's rules</a>. This information was used in feature engineering.  
								In the first, investigatory paper, data on arrests in NYC and stop, question, and frisk patterns were investigated. Please visit <a href = "https://data.cityofnewyork.us/Public-Safety/NYPD-Arrests-Data-Historic-/8h9b-rp9u">this link </a> for the arrests data and 
								<a href = "https://data.cityofnewyork.us/Public-Safety/The-Stop-Question-and-Frisk-Data/ftxv-d5ix">this link</a> for the stop, question, and frisk data. 
							</p>

							<h2>The Logistic Regression Model</h2>
							<p>
								A simple logistic regression model with with L2 regularization was used to model the CCRB's decision process. 
								To train the model, a simple 75%-25% train-test split was used. 
								To combat the class imbalance present (only about 25% of complaints were deemed substantiated), the <code>class_weight</code> hyperparameter, which assigns a weight to each class that the model uses for penalizing, was used. 
								In order to determine the proper decision thereshold, different utility functions were compared, ultimately leading to a threshold of 0.527 instead of the default 0.5. 
								This means that anything that the model classifies points as substantiated if the resulting regression prediction is at least 0.527. See the paper for more details. 

							</p>
							<h3>Features</h3>
							<p>
								The features used in the model are:
							</p>
							<ul>
								<li><code>contact_reason</code> (or text indicating why the officer approached the civilian)</li>
								<li><code>mos_ethinicity</code> (officer's ethnicity), rank_incident (officer's rank at time of incident)</li>
								<li><code>mos_gender</code> (officer's gender)</li>
								<li><code>complainant_gender</code> (omplainant's gender)</li>
								<li><code>mos_age_incident</code> (oofficer's age at time of incident)</li>
								<li><code>complainant_age_incident</code> (complainant's age at time of incident)</li>
								<li><code>borough</code> (the borough in which the incident took place)</li>
								<li><code>black</code> (whether the complainant is Black)</li>
								<li><code>allegation</code> (brief description of the allegation)</li>
								<li><code>fado_type</code> (type of complaint)</li>
								<li>time/date related features (`month_received`, `year_received`, `month_closed`, and `year_closed`)/li>
							</ul>

							<p>
								All categorical features except allegation and fado_type were one-hot encoded while the exceptions were ordinal encoded. The numerical features were scaled. 
							</p>

							<h3>Evaluation Metrics</h3>
							<p>
								The class imbalance makes accuracy ill-suited for this model, so the F1 score was used instead. The test performance metrics for all groups is as follows:
								<ul>
									<li>Accuracy Score: 0.623882406425216</li>
									<li>Recall score: 0.526413921690491</li>
									<li>Precision score: 0.3299571484222828</li>
									<li>F1 score: 0.4056513409961685</li>
							</p>

							<h2>Overview of Parity Measures and Fairness Results</h2>
							<p>
								For a breakdown of different parity measures and fairness in machine learning, take a look at <a href = "https://developers.google.com/machine-learning/glossary/fairness">Google's Machine Learning Glossary: Fairness</a>.
								With the original model, a singular threshold was used. Under this model, both demographic parity and equalized odds were not satisfied, but predictive value parity was met. The original model substantiated complaints from Black civilians far less often than it did for non-Black complainants. The violation in equalized odds means the model gave more complaints submitted by non-Black complainants the “benefit of the doubt” and classified more CCRB-unsubstantiated complaints as substantiated than for Black complainants.
								To try and improve these metrics for fairness, 2 different threshold tests were conducted to find better thresholds based on groups (complainant ethnicity in this case). Firstly, the thresholds that maximize utility for the individual group were used. These thresholds satisfied demographic parity and equalized odds, but not predictive value parity. Secondly, the thresholds that satisfy the 3 parity measures (demographic parity, equalized odds, and predictive value parity) were found using the training data and then tested with a separate dataset. See the paper for a more in depth breakdown on how these tests were conducted.
								Depending on what is most important to the decision-making body (CCRB), different threshold(s) would be chosen. Maximizing utility overall enforces equality for all complainants, while maximizing utility for each group is more equitable. Satisfying demographic parity ensures that substantiation doesn’t depend on complainant ethnicity. Equality of odds would focus on ensuring that the chance of obtaining the benefit of substantiation is equal across groups, while predictive value parity focuses on ensuring deserving complainants receive substantiation and underserving complainants don't. The table below demonstrates different group thresholds that could be used, depending on the goal (maximizing utility or enforcing a parity measure).
							</p>

							<table>
								<tr>
								  <th>Threshold for Black Complainants</th>
								  <th>Threshold for non-Black Complainants</th> 
								  <th>Test</th>
								  <th>Demographic Parity</th>
								  <th>Equality of Odds</th>
								  <th>Predictive Value Parity</th>
								</tr>
								<tr>
								  <td>0.527s</td>
								  <td>0.527</td> 
								  <td>Max utility overall</td>
								  <td>Not satisfied</td>
								  <td>Not satisfied</td>
								  <td>Satisfied</td>
								</tr>
								<tr>
									<td>0.522</td>
								  <td>0.546</td> 
								  <td>Max utility per group</td>
								  <td>Satisfied</td>
								  <td>Not satisfied</td>
								  <td>Not atisfied</td>
								</tr>
								<tr>
									<td>0.522</td>
								  <td>0.541</td> 
								  <td>Enforce equality of odds</td>
								  <td>N/A</td>
								  <td>Strictly satisfied</td>
								  <td>N/A</td>
								</tr>
								<tr>
									<td>0.522</td>
								  <td>0.535</td> 
								  <td>Enforce predictive value parityl</td>
								  <td>N/A</td>
								  <td>N/A</td>
								  <td>Not atisfied</td>
								  </tr>

							  </table>

							  <h2>Conclusion</h2>
							  <p>
								Hopefully this paper shows that often times, an algorithm or model may (unintentionally) be unfair or inequitable if such parity measures or metrics of fairness are not considered. As for this specific example of the CCRB, the model missses out on lots of data perhaps gathered in the investigation process, but still demonstrates evidence of inequities or unfairness. The bottom line is that any model or algorithm absolutely should consider its fairness! 

							  </p>

                        </article>
						<!-- Results -->
							<article id="positions">
								<h1 id="nba-players-position-classifier">NBA Players Position Classifier</h1>
<p><img src="images/positionless-nba-2.png" alt="banner"></p>
<p><a href="https://www.cbssports.com/nba/news/power-guard-point-center-the-nbas-positional-misfits-are-dismantling-an-antiquated-system/">SOURCE</a></p>
<h1 id="links">Links</h1>
<ul>
<li><a href="https://jacquelinekclee.github.io/nba-players-position-classifier/">Website</a></li>
<li><a href="https://github.com/jacquelinekclee/nba-players-position-classifier">Repository (with all relevant files/data)</a></li>
</ul>
<h1 id="table-of-contents">Table of contents</h1>
<ul>
<li><a href="#background">Background</a></li>
<li><a href="#the-statistics">The Statistics</a></li>
<li><a href="#statistics-source">Statistics Source</a></li>
<li><a href="#the-methodology">The Methodology</a><ul>
<li><a href="#training">Training</a></li>
<li><a href="#final-model">Final Model</a></li>
</ul>
</li>
<li><a href="#usage">Usage</a></li>
<li><a href="#findings">Findings</a></li>
<li><a href="#source-file">Source File</a></li>
<li><a href="#legality">Legality</a></li>
</ul>
<h2 id="background">Background</h2>
<p>As someone who has been playing basketball since the second grade and has been a Warriors fan since birth, the NBA and basketball in general have always held a special place in my heart. As time goes on, statistics and analytics have played an increasingly larger role in the world of basketball. With this project, and my <a href="https://jacquelinekclee.github.io/nba-all-stars-classifier.github.io/">NBA All Stars Classifier</a>, I wanted to use my love of basketball in developing and praciticing new Data Science skills.</p>
<p>As basketball players have gotten more skilled and talented and as the game itself has revolutionized, the notion of positions increasingly becomes a dated aspect of the game. The commissioner of the NBA, Adam Silver, acknowledged that the NBA <a href="https://www.nba.com/news/nba-commissioner-adam-silver-discusses-leagues-positionless-basketball-at-annual-finals-press-conference">&quot;has moved increasingly to positionless basketball&quot;</a> when discussing the possibility of removing positions from the All-NBA decision process, which honors the best players in the league. </p>
<p>With this project, I hope to understand basketball positions using statistics and machine learning. If an ML model can predict a player&#39;s position based on his stats, then maybe this player doesn&#39;t play positionless basketball and adheres to his traditional role as a guard/forward/center. If a model gets it wrong, then maybe the player has a unique play style that doesn&#39;t conform to the historic statistics of players in his positions before him. </p>
<p>Keep reading to learn more about the data used, the approach I took to building this classifier, and the cool findings the model yielded!</p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="the-statistics">The Statistics</h2>
<p>The NBA tracks almost 50 different statistics for every player in the league. Many statistics are often unknown to most basketball fans, so using only the common statistics will make the most sense for everyone. 
Here are some basic definitions of the statistics I will be using in my classifier:</p>
<ul>
<li>True shooting percentage (TS%): a metric that demonstrates how efficiently a player shoots the ball. Takes into consideration field goals, 3-pointers, and free throws (unlike other metrics like field goal percentage).</li>
<li>Rebounds per game (RPG): a metric that shows how many total rebounds (both offensive and defensive) a player averages per game. </li>
<li>Assists per game (APG): a metric that shows how many total assists a player averages per game.</li>
<li>Points per game (PPG): a metric that shows how many total points a player averages per game.</li>
<li>Blocks per game (BPG): a metric that shows how many total blocks a player averages per game.</li>
<li>Steals per game (SPG): a metric that shows how many total steals a player averages per game.</li>
</ul>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="statistics-source">Statistics Source</h2>
<p>The training data comes from <a href="https://www.kaggle.com/drgilermo/nba-players-stats?select=Seasons_Stats.csv">Kaggle</a>. The test data come from <a href="https://www.basketball-reference.com/">Basketball Reference</a>:</p>
<ul>
<li><a href="https://www.basketball-reference.com/leagues/NBA_2019_per_game.html">2018-19 Data</a></li>
<li><a href="https://www.basketball-reference.com/leagues/NBA_2021_per_game.html">2020-21 Data</a></li>
<li><a href="https://www.basketball-reference.com/leagues/NBA_2022_per_game.html">2021-22 Data</a></li>
</ul>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="usage">Usage</h2>
<p>Please refer to the <a href="https://nbviewer.org/github/jacquelinekclee/nba-players-position-classifier/blob/0d3b4b07abce345b5b50566b95ac793e7ba10c5d/nba_positions_classifier.ipynb">Jupyter Notebook Viewer</a> or the <a href="https://github.com/jacquelinekclee/nba-players-position-classifier/blob/0d3b4b07abce345b5b50566b95ac793e7ba10c5d/nba_positions_classifier.ipynb">.ipynb file</a> to view all the code for the classifier. The notebook with all the data cleaning can be seen <a href="https://github.com/jacquelinekclee/nba-players-position-classifier/blob/0d3b4b07abce345b5b50566b95ac793e7ba10c5d/nba_players_data_cleaning.ipynb">here</a>. </p>
<p>The <a href="#source-file">source file</a> contains all the functions used to clean/manipulate the data and DataFrames.</p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="the-methodology">The Methodology</h2>
<p>In the initial data cleaning process, the players&#39; positions were simplified to include 5 classes: </p>
<table>
<thead>
<tr>
<th style="text-align:left">Position</th>
<th style="text-align:right">Proportion in Training Data</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Forward</td>
<td style="text-align:right">0.399</td>
</tr>
<tr>
<td style="text-align:left">Guard</td>
<td style="text-align:right">0.396</td>
</tr>
<tr>
<td style="text-align:left">Center</td>
<td style="text-align:right">0.199</td>
</tr>
<tr>
<td style="text-align:left">Guard/Forward</td>
<td style="text-align:right">0.003</td>
</tr>
<tr>
<td style="text-align:left">Forward/Center</td>
<td style="text-align:right">0.003</td>
</tr>
</tbody>
</table>
<p>Notice that forwards and guards make up nearly 80% of the datasest, with centers making just under 20% and the hybrid positions making up hardly 1% altogether. Since this is a multiclass problem with some class imbalance, I wanted to test different models. Another consideration was the effect of including Year as a feature. Theoretically, if the way a player of a given position hasn&#39;t changed over time, then a classifier without year should perform better (or differently) than a classifier with year as a feature. </p>
<p>I tried both random forest modesl and XGBoost models. I went with random forests as a better alternative to decision trees in that random forests are more robust to overfitting. I also chose to explore XGBoost classifiers as they might work better for the class imbalance. In total, 4 different models were originally trained: 2 random forests (one with year as a featuere and one without) and 2 XGBoost classifiers (one with year as a feature and one without). The features for both models were as follows:</p>
<ul>
<li>TS%: true shooting percentage</li>
<li>RPG: rebounds per game</li>
<li>APG: assists per game</li>
<li>PPG: points per game</li>
<li>BPG: blocks per game</li>
<li>SPG: steals per game</li>
<li>Year: year of that season (e.g, rows from the 1980-1981 season has 1981 as its year)</li>
<li>All Star: whether that player was an All Star that season</li>
<li>MVP: whether that player was the MVP that season</li>
</ul>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="training">Training</h2>
<p>Using Scikit&#39;s <code>GridSearchCV</code>, I tested out several combinations of different hyperparameters. The training times for both models were extremely <em>long</em>. See below for the paramters tested for each type of model:</p>
<p>Parameters tested for random forests:
<code>{&#39;n_estimators&#39;: [300,500,700], &#39;max_features&#39;: [&#39;sqrt&#39;, &#39;log2&#39;], &#39;max_depth&#39; : [5,10,15,20,25,None], &#39;criterion&#39; :[&#39;gini&#39;, &#39;entropy&#39;], &#39;random_state&#39; : [18]}</code></p>
<p>Parameters tested for XGBoost classifiers:
<code>{&#39;max_depth&#39;: [3,6,10], &#39;learning_rate&#39;: [0.01, 0.05, 0.1], &#39;n_estimators&#39;: [100, 500, 1000], &#39;colsample_bytree&#39;: [0.3, 0.7]}</code></p>
<p>Given that this a multiclass classification problem, I found that accuracy was the most straightforward evaluation metric. Additionally, I looked at the proportion of players for a given position that were misclassified. For example, if 10 out of 40 centers in the test data set were <em>not</em> classified as centers by the model, then the proportion would be 0.25. See below for the results found with the 2018-19 season as the test set:</p>
<table>
<thead>
<tr>
<th style="text-align:left">model</th>
<th style="text-align:right">test accuracy</th>
<th style="text-align:right">prop wrong for centers</th>
<th style="text-align:right">prop wrong for forwards</th>
<th style="text-align:right">prop wrong for guards</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">random forest without year</td>
<td style="text-align:right">0.390</td>
<td style="text-align:right">0.48</td>
<td style="text-align:right">0.19</td>
<td style="text-align:right">0.26</td>
</tr>
<tr>
<td style="text-align:left">random forest with year</td>
<td style="text-align:right">0.392</td>
<td style="text-align:right">0.47</td>
<td style="text-align:right">0.19</td>
<td style="text-align:right">0.23</td>
</tr>
<tr>
<td style="text-align:left">XGBoost without year</td>
<td style="text-align:right">0.378</td>
<td style="text-align:right">0.53</td>
<td style="text-align:right">0.2</td>
<td style="text-align:right">0.27</td>
</tr>
<tr>
<td style="text-align:left">XGBoost with year</td>
<td style="text-align:right">0.390</td>
<td style="text-align:right">0.55</td>
<td style="text-align:right">0.16</td>
<td style="text-align:right">0.25</td>
</tr>
</tbody>
</table>
<p>Both types of model performed better when year was included in the feature set, with year boosting accuracy more for the XGBoost models than the random forests. What stuck out to me most was how much better the random forests were at classifying the minority class, centers. </p>
<p>Additionally, the 2 types of classifiers found different features to be more important. The Random Forest classifiers thought RBG (rebounds per game) were more important than BPG (blocks per game), while the XGBoost classifiers didn&#39;t. Both classifiers had similar levels of feature importance for APG (assists per game) and PPG (points per game). See the notebook for feature importances. </p>
<p>Some pitfalls of both classifiers include: </p>
<ul>
<li>Neither classifier was able to classify the hybrid positions, GF and FC, correctly. This is likely because only about 0.006 of the training data have these hybrid positions. </li>
<li>Both the All Star and MVP features had 0 importance for all 4 models tested. Including irrelevant features could make cost (e.g., runtime) unnecessarily high. </li>
<li>Although XGBoost was used to try and combat the class imbalance (around 2x guards and forwards than centers), XGBoost did <em>worse</em> and classifying centers than Random Forest did. </li>
</ul>
<p>In effort to create a better performing classifier, a new position column will be created. Hopefully making this problem only 3 classes instead of 5 will yield a better classifier. Also, MVP and All Star will be removed from the feature list. It seems that the year feature is particularly useful for classifying guards. Lastly, although XGBoost yielded a slightly higher accuracy, it classified centers much worse than the random forest (which was unexpected). Since the XGBoost didn&#39;t provide the expected benefits and its training time is much slower, Random Forest will be used going forward. </p>
<h2 id="final-model">Final Model</h2>
<p>Based on the findings above, I went with a Random Forest model with TS%, RPG, APG, PPG, BPG, SPG, and Year as features. See below for the feature importances and test accuracies:</p>
<table>
<thead>
<tr>
<th style="text-align:left">Feature</th>
<th style="text-align:right">Importance</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">RPG</td>
<td style="text-align:right">0.254</td>
</tr>
<tr>
<td style="text-align:left">APG</td>
<td style="text-align:right">0.251</td>
</tr>
<tr>
<td style="text-align:left">BPG</td>
<td style="text-align:right">0.233</td>
</tr>
<tr>
<td style="text-align:left">SPG</td>
<td style="text-align:right">0.116</td>
</tr>
<tr>
<td style="text-align:left">PPG</td>
<td style="text-align:right">0.077</td>
</tr>
<tr>
<td style="text-align:left">TS%</td>
<td style="text-align:right">0.037</td>
</tr>
<tr>
<td style="text-align:left">Year</td>
<td style="text-align:right">0.031</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left">season</th>
<th style="text-align:right">test accuracy</th>
<th style="text-align:right">prop wrong for centers</th>
<th style="text-align:right">prop wrong for forwards</th>
<th style="text-align:right">prop wrong for guards</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">2018-19</td>
<td style="text-align:right">0.736</td>
<td style="text-align:right">0.47</td>
<td style="text-align:right">0.19</td>
<td style="text-align:right">0.24</td>
</tr>
<tr>
<td style="text-align:left">2020-21</td>
<td style="text-align:right">0.715</td>
<td style="text-align:right">0.46</td>
<td style="text-align:right">0.22</td>
<td style="text-align:right">0.27</td>
</tr>
<tr>
<td style="text-align:left">2021-22</td>
<td style="text-align:right">0.704</td>
<td style="text-align:right">0.54</td>
<td style="text-align:right">0.19</td>
<td style="text-align:right">0.27</td>
</tr>
</tbody>
</table>
<p>Clearly, this model performed much better than the 1st round. However, it started performing worse for the more recent seasons. This may be some indication of a shift coming in basketball, where players&#39; statistics and general playstyles don&#39;t reflect the typical notions of positions in seasons prior. </p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="findings">Findings</h2>
<p>Draymond Green, Ben Simmons, Giannis Antetokounmpo, LeBron James, Kevin Durant, Nikola Jokić, and Jayson Tatum are some consensus &quot;positionless&quot; NBA players (see this <a href="&#39;https://bleacherreport.com/articles/2627364-5-unique-nba-players-who-dont-fit-in-a-category&#39;">CBS article</a> and this <a href="&#39;https://bleacherreport.com/articles/2627364-5-unique-nba-players-who-dont-fit-in-a-category&#39;">Blearcher Report article</a>). One might expect the classifier to predict these players&#39; posititions <em>incorrectly</em> if they are truly &quot;positionless.&quot; As with all things basketball, several things transcend the stat sheet, but hopefully these results provide some interesting insights! The table below shows the correct position (Pos) and the model&#39;s prediction (pos_pred) for these &quot;positionless&quot; players:</p>
<table>
<thead>
<tr>
<th style="text-align:left">Player</th>
<th style="text-align:left">Pos_2019</th>
<th style="text-align:left">pos_pred_2019</th>
<th style="text-align:left">Pos_2021</th>
<th style="text-align:left">pos_pred_2021</th>
<th style="text-align:left">Pos</th>
<th style="text-align:left">pos_pred</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Giannis Antetokounmpo</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
</tr>
<tr>
<td style="text-align:left">Kevin Durant</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
</tr>
<tr>
<td style="text-align:left">Draymond Green</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">G</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
</tr>
<tr>
<td style="text-align:left">LeBron James</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">G</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
</tr>
<tr>
<td style="text-align:left">Nikola Jokić</td>
<td style="text-align:left">C</td>
<td style="text-align:left">F</td>
<td style="text-align:left">C</td>
<td style="text-align:left">F</td>
<td style="text-align:left">C</td>
<td style="text-align:left">F</td>
</tr>
<tr>
<td style="text-align:left">Jayson Tatum</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
</tr>
</tbody>
</table>
<p>Giannis Antetokounmpo, Kevin Durant, and Jayson Tatum were always correctly classified as forwards for the 3 seasons used as test data. This may be because forwards were the most common position in the training data, so the classifier knows forwards particularly well. </p>
<p>Basketball Reference has LeBron James listed as having played both the forward and guard positions. In the 2020-21 season, where James was listed primarily as a guard, the classifier predicted him incorrectly to be a forward. In the eyes of the classifier, it seems that James presents as a forward more than a guard.</p>
<p>In the 2020-21 season, Draymond Green was listed as a forward, but misclassified as a guard. Green had to step up that season considering Klay Thompson&#39;s absence that season and the fact that other guards like Jordan Poole (playing only his 3rd year professionaly after some time in the G-League) and Gary Payton II (who hardly played at all) were early in their development. </p>
<p>Hopefully some of these insights were interesting! Please feel free to explore the Python notebooks on your own!</p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="source-file">Source File</h2>
<ul>
<li><a href="https://github.com/jacquelinekclee/nba-players-position-classifier/blob/0d3b4b07abce345b5b50566b95ac793e7ba10c5d/nba_players_classification.py">nba_players_classification.py</a><ul>
<li>Has all the functions used for mainly the data cleaning.</li>
</ul>
</li>
</ul>
<h2 id="legality">Legality</h2>
<p>This personal project was made for the sole intent of applying my skills in Python thus far and as a way to learn new ones. It is intended for non-commercial uses only.</p>
<p><a href="#table-of-contents">(Back to top)</a></p>

								
						</article>

						<!-- Contact -->
							<article id="concl">
                                <h1 style = "text-align:center">Conclusion</h1>
								<p> TWAS was ultimately able to identify 7 genes that are associated with IBD. One of the genes, A4GALT, did not have any genome-wide significant GWAS SNPs nearby. This highlights that TWAS is able to find signals that may not be capable using only GWAS SNPs. Our findings can be verified by other sources. For example, Marigorta et. al (2017) showed that there was an association between SYNGR1 and IBD, which our analysis also identified. Identification of these genes can be useful for disease prevention and early detection
								</p>

							</article>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<p class="copyright">&copy; Group 1 Project A17. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
					</footer>

			</div>

		<!-- BG -->
			<div id="bg"></div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>