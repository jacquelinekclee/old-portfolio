<!DOCTYPE HTML>
<!--
	Dimension by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Jacqueline Lee's Portfolio</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="logo">
							<div class="container">
								<span style="color: rgb(177, 136, 252)", class="icon fa-home"></span>
							</div>
						</div>
						<div class="content">
							<br>
							<p>
								<span class="center"><img src="images/tcg_headshot.jpg" alt="" width="300" height="300"/></span>
								<style>
								img {
								  display: block;
								  margin-left: auto;
								  margin-right: auto;
								}
								</style>
								<h1>Jacqueline Lee</h1>
								
							</p>
							<p style="color: rgba(255, 255, 255, 2.5); font-size:160%;">
								<i class="fa fa-envelope-open fa3x"></i> <a href="mailto:jacquelinekclee@yahoo.com"> E-Mail </a>

								<svg xmlns="http://www.w3.org/2000/svg" width="50" height="50" fill="currentColor" class="bi bi-linkedin" viewBox="0 0 16 16">
									<path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854V1.146zm4.943 12.248V6.169H2.542v7.225h2.401zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248-.822 0-1.359.54-1.359 1.248 0 .694.521 1.248 1.327 1.248h.016zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016a5.54 5.54 0 0 1 .016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225h2.4z"/>
								</svg> <a href="https://www.linkedin.com/in/jacqueline-kc-lee/">LinkedIn</a>

								<svg xmlns="http://www.w3.org/2000/svg" width="50" height="50" fill="currentColor" class="bi bi-github" viewBox="0 0 16 16">
									<path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"/>
								</svg> <a href="https://github.com/jacquelinekclee">GitHub</a>
							</p>
							<div class="inner">

								<p style="color: rgba(255, 255, 255, 0.89); font-size:120%;">
									Hello! I'm Jacqueline, a UC San Diego alum with a B.S. in Data Science and minors in Economics and Business. Welcome to my portfolio! 
									<br>Here, you'll find all of the Data Science projects I've done since I've started my Data Science journey back in 2019. 
									<br>Click on the links above to contact me and scroll down to learn more about my experience!
								</p>
								<br>
								<p style="color: rgba(255, 255, 255, 0.89); font-size:120%;">click on these boxes to look at the different projects i've done!</p>
								<nav class>
									<h5 style="color: rgba(255, 255, 255, 0.89)"> 
										<a style="border-width:3px; border-style:solid; border-color:rgb(177, 136, 252); padding: 1em; text-align:center" href="#positions"> <u>Random Forest/XGBoost: NBA Positions Classifier</u> </a> 
										<a style="border-width:3px; border-style:solid; border-color:rgb(177, 136, 252); padding: 1em; text-align:center" href="#hiphop"> <u>NLP/Webscraping: Has Hip Hop Gotten Worse?</u> </a> 
					
									</h5>
								</nav>
								<br>
								<nav class>
									<h5 style="color: rgba(255, 255, 255, 0.89)"> 
										
										<a style="border-width:3px; border-style:solid; border-color:rgb(177, 136, 252); padding: 1em; text-align:center" href="#allstars"> <u>KNN: NBA All Stars Classifier</u> </a> 
										<a style="border-width:3px; border-style:solid; border-color:rgb(177, 136, 252); padding: 1em; text-align:center" href="https://jacquelinekclee.github.io/nba-data-viz-d3.github.io/"> <u>JavaScript/D3: NBA Data Viz</u> </a> 
										<a style="border-width:3px; border-style:solid; border-color:rgb(177, 136, 252); padding: 1em; text-align:center" href="#nypd"> <u>Ethics: Is the NYPD Fair?</u> </a> 
									</h5>
								</nav>
								
							</div>
						</div>
						
						<h1 style = "text-align:center">About Me</h1>
						<p style="color: rgba(255, 255, 255, 2.5); font-size:160%;">
							<i class="fa fa-envelope-open fa3x"></i> <a href="mailto:jacquelinekclee@yahoo.com"> E-Mail </a>
	
							<svg xmlns="http://www.w3.org/2000/svg" width="50" height="50" fill="currentColor" class="bi bi-linkedin" viewBox="0 0 16 16">
								<path d="M0 1.146C0 .513.526 0 1.175 0h13.65C15.474 0 16 .513 16 1.146v13.708c0 .633-.526 1.146-1.175 1.146H1.175C.526 16 0 15.487 0 14.854V1.146zm4.943 12.248V6.169H2.542v7.225h2.401zm-1.2-8.212c.837 0 1.358-.554 1.358-1.248-.015-.709-.52-1.248-1.342-1.248-.822 0-1.359.54-1.359 1.248 0 .694.521 1.248 1.327 1.248h.016zm4.908 8.212V9.359c0-.216.016-.432.08-.586.173-.431.568-.878 1.232-.878.869 0 1.216.662 1.216 1.634v3.865h2.401V9.25c0-2.22-1.184-3.252-2.764-3.252-1.274 0-1.845.7-2.165 1.193v.025h-.016a5.54 5.54 0 0 1 .016-.025V6.169h-2.4c.03.678 0 7.225 0 7.225h2.4z"/>
							</svg> <a href="https://www.linkedin.com/in/jacqueline-kc-lee/">LinkedIn</a>
	
							<svg xmlns="http://www.w3.org/2000/svg" width="50" height="50" fill="currentColor" class="bi bi-github" viewBox="0 0 16 16">
								<path d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z"/>
							</svg> <a href="https://github.com/jacquelinekclee">GitHub</a>
							<h3 style="color: rgba(255, 255, 255, 0.89)"> 
								<a style="border-width:3px; border-style:solid; border-color:rgb(177, 136, 252); padding: 1em; text-align:center" href="#resume_download"> <u>Download My Resume</u> </a> 
							</h3>
						</p>
						<h1>Education</h1>
						<div class="resume">
							<!-- <div class="image">
							  <img class = "resume_image" src="images/hdsi.png">
							</div> -->
							<img class = "resume_image" src="images/hdsi.png">
							<div style = "padding-left: 20px; text-align: left;">
							  <h2>UC San Diego</h2>
							  <h3>B.S. Data Science</h3>
							  <h4>Minors in Economics and Business</h4>
							  <p>
								  <ul>
									  <li>GPA: 3.97</li>
									  <li>Courses: Practice and Application of Data Science; Intro to Machine Learning<br>Business Analytics;
										SQL – Intro to Data Management; JavaScript/D3 – Intro to Data Visualization; Deep Learning
										</li>
								  </ul>
							  </p>
							</div>
						</div>
	
						<br>
						<h1>Skills</h1>
	
						<div class="gallery">
							<figure class="gallery__item gallery__item--1">
							  <img src="images/python.png" class="gallery__img" alt="Image 1">
							</figure>
							<figure class="gallery__item gallery__item--2">
							  <img src="images/rubyrails.png" class="gallery__img" alt="Image 2">
							</figure>
							<figure class="gallery__item gallery__item--3">
							  <img src="images/sql.png" class="gallery__img" alt="Image 3">
							</figure>
							<figure class="gallery__item gallery__item--4">
							  <img src="images/pandas.png" class="gallery__img" alt="Image 4">
							</figure>
							<figure class="gallery__item gallery__item--5">
							  <img src="images/numpy.png" class="gallery__img" alt="Image 5">
							</figure>
							<figure class="gallery__item gallery__item--6">
							  <img src="images/aws.png" class="gallery__img" alt="Image 6">
							</figure>
							<figure class="gallery__item gallery__item--7">
								<img src="images/scikitsquare copy.jpg" class="gallery__img" alt="Image 6">
							</figure>
							<figure class="gallery__item gallery__item--8">
								<img src="images/jupyter.png" class="gallery__img" alt="Image 6">
							</figure>
							<figure class="gallery__item gallery__item--9">
								<img src="images/git.jpg" class="gallery__img" alt="Image 6">
							</figure>
						</div>
						<br>
	
						<h1>Work Experience</h1>
						<div class="resume">
							<!-- <div class="image">
							  <img class = "resume_image" src="images/ballertv.jpg">
							</div> -->
							<img class = "resume_image" src="images/ballertv.jpg">
							<div style = "padding-left: 20px; text-align: left;">
							  <h2>Software Engineer Intern</h2>
							  <a href="https://www.ballertv.com/about-us"> <h3><u>BallerTV</u></h3></a>
							  <h4>Jun 2022 - Aug 2022</h4>
							  <p >
								<ul>
									<li>Developed a program that cleans basketball scoring data, extracts relevant statistics, and feeds them into Natural Language Generation tool to automatically create customized headlines for thousands of games.</li>
									<li>Created dashboards (Redash, SQL) that highlight relevant metrics regarding travel costs and asset tracking to enable product managers and stakeholders to make cost-saving decisions.</li>
									<li>Programmed a workflow that automatically sends text messages to hired contractors when an event is postponed by leveraging Active Record and Twilio API, ensuring timely and appropriate communication.</li>
								</ul>
							  </p>
							</div>
						</div>
						<br>
						<div class="resume">
							<!-- <div class="image">
							  <img class = "resume_image" src="images/bess.png">
							</div> -->
							<img class = "resume_image" src="images/bess.png">
							<div style = "padding-left: 20px; text-align: left;">
							  <h2>Fellow</h2>
							  <a href="https://www.bvp.com/bessemer-fellows"> <h3><u>Bessemer Venture Partners</u></h3></a>
							  <h4>Jun 2022 - Aug 2022</h4>
							  <p>
								<ul>
									<li>1 of 20 fellows chosen out of 2,000+ applications and 60+ finalists; portfolio company directly reached out.</li>
									<li>Studied entrepreneurship with founders and product leaders in the venture capital space.</li>
								</ul>
							  </p>
							</div>
						</div>
						<br>
						<div class="resume">
							<!-- <div class="image">
							  <img class = "resume_image" src="images/te.png">
							</div> -->
							<img class = "resume_image" src="images/te.png">
							<div style = "padding-left: 20px; text-align: left;">
							  <h2>Data Science Intern</h2>
							  <a href="https://www.te.com/usa-en/home.html"> <h3><u>TE Connectivity</u></h3></a>
							  <h4>Jun 2021 - Jun 2022</h4>
							  <p>
								<ul>
									<li>Analyzed deep learning forecast model results with Pandas and identified 1,000+ highly accurate parts making $300M+ in revenue to educate executives on cost-saving forecast model and promote its adoption.</li>
									<li>Developed a fuzzy matching algorithm in Python that maps predictions to actual sales, quantifies success of marketing campaigns, increased accuracy by 50%, and was adopted on 2 projects used by 5+ departments.</li>
									<li>Coded statistical methodology using Python/SciPy that randomly splits potential customers into a test and control groups, reducing manual labor and enabling marketers to accurately evaluate their campaigns.</li>
								</ul>
							  </p>
							</div>
						</div>
						<br>
						<div class="resume">
							<!-- <div class="image">
							  <img class = "resume_image" src="images/hdsi.png" >
							</div> -->
							<img class = "resume_image" src="images/hdsi.png" >
							<div style = "padding-left: 20px; text-align: left;">
							  <h2>Data Science Tutor</h2>
							  <a href="https://datascience.ucsd.edu/academics/undergraduate/dsc-tutors/"> <h3><u>Halıcıoğlu Data Science Institute</u></h3></a>
							  <h4>Oct 2020 - Mar 2023</h4>
							  <p>
								<ul>
									<li>Enhanced students’ Python and Java skills in topics like object-oriented programming, recursion, and data structures by helping them understand assignments and coding logic during 4 weekly office hours. </li>
									<li>Reinforced lecture material through creating weekly quizzes, moderated the question and answer forum to resolve students’ issues, and contributed to the creation of programming assignments.</li>
								</ul>
							  </p>
							</div>
						</div>
						
						<br>
						<h1>Leadership</h1>
						<div class="resume">
							<!-- <div class="image">
							  <img class = "resume_image" src="images/ucsd.png">
							</div> -->
							<img class = "resume_image" src="images/ucsd.png">
							<div style = "padding-left: 20px; text-align: left;">
							  <h2>Chair</h2>
							  <a href="https://vcsa.ucsd.edu/sfac/index.html"> <h3><u>UCSD Student Fee Advisory Committee</u></h3></a>
							  <h4>May 2021 - May 2022</h4>
							  <p>
								<ul>
									<li>Led committee of 20+ student representatives and staff members to provide the Vice Chancellor of Student Affairs with students’ perspective on how $40M in student fees should be allocated.</li>
									<li>Analyzed 16 budget proposal requests and crafted a report that details the committee’s funding recommendations, leading to nearly $1 million in funding allocations for student services.</li>
									<li>Implemented an equity scorecard to better tailor committee’s rankings to the university’s values of diversity, equity, and inclusion and to encourage holistic scoring of each budget proposal request.</li>
								</ul>
							  </p>
							</div>
						</div>
						<div class="resume">
							<!-- <div class="image">
							  <img class = "resume_image" src="images/tcg.webp">
							</div> -->
							<img class = "resume_image" src="images/tcg.webp">
							<div style = "padding-left: 20px; text-align: left;">
							  <h2>Project Manager</h2>
							  <a href="https://www.ucsdtcg.org"> <h3><u>Triton Consulting Group</u></h3></a>
							  <h4>Oct 2019 - Mar 2022</h4>
							  <p>
								<ul>
									<li>Supervised team of 5 associates that developed customer acquisition strategies and marketing and advertising tactics for <a href="https://www.caked.love"><u>bakery</u></a> looking to improve its B2B and B2C business mid- and post-pandemic.</li>
									<li>Performed market research, analyzed 2 competitors’ social media followers using Pandas, and leveraged that data in order to give beauty brand insights into who its typical customer is.</li>
									<li>Provided pro-bono consulting services for local businesses and startups and fostered university’s business community by holding recruitment of 50+ students each quarter.</li>
								</ul>
							  </p>
							</div>
						</div>	
						
					</header>

					
								
				<!-- Main -->
					<div id="main">

						<!-- Intro -->
							<article id="resume_download">
                                
                                <h1 style = "text-align:center">Resume</h1>
								<iframe src="files/jacqueline_lee_resume_0123.pdf#toolbar=0" width="100%" height="2000px">
								</iframe>
								
							</article>

						<!-- Work -->
							<article id="nypd">
                                <h1 style = "text-align:center">Algorithmic Audit: Modeling the New York City Civilian Complaint Review Board and Auditing the Model Fairness</h1>

								<span class="center"><img src="images/Screen Shot 2022-09-08 at 5.37.33 PM-2.png" alt="" width="50%"/></span>
                            <style>
                                img {
                                  display: block;
                                  margin-left: auto;
                                  margin-right: auto;
                                }
                            </style>
							<h2>For full paper, <a href="https://github.com/jacquelinekclee/algorithmic-audit-nyc-ccrb/blob/aa536a7c4a71f71eaf114cd817be665e8a0b5252/paper2.pdf"> <u>click here</u> </a> </h2>
							<h2>For paper covering the background/investigation of inequity, <a href="https://github.com/jacquelinekclee/algorithmic-audit-nyc-ccrb/blob/08a597c91e40e83a4332684390dc4a4e5afbdf06/paper1.pdf"> <u>click here</u> </a> </h2>
   
							<p>
								Please note that this functions only as an overview of the work done! Please take a look at the final papers (linked above) or their corresponding Python notebooks:
								<ul>
									<li><a href="https://github.com/jacquelinekclee/algorithmic-audit-nyc-ccrb/blob/4120ace9bea5f2d2045f8d984f68f158b23f94f9/Paper%202%20-%20Modeling%20the%20New%20York%20City%20Civilian%20Complaint%20Review%20Board%20and%20Auditing%20the%20Model%20Fairness.ipynb"> <u>Algorithmic Audit Python Notebook Link</u> </a></li>
									<li><a href="https://github.com/jacquelinekclee/algorithmic-audit-nyc-ccrb/blob/4120ace9bea5f2d2045f8d984f68f158b23f94f9/Paper%201%20-%20Inequities%20in%20Civilian%20Complaints%20to%20the%20NYPD.ipynb"> <u>Inequities in Civilian Complaints to the NYPD Link</u> </a></li>
								</ul
							</p>		
							
							<h2>Background</h2>
							<p>This paper and analysis was done during Spring 2022 as part of the course <a href="https://afraenkel.github.io/fairness-algo-decision/"> <u>DSC 167</u> </a>: Fairness and Algorithmic Decision Making at UC San Diego's Halıcıoğlu Data Science Institute. 
								The purpose of the assignment and aim of this paper was to find a system or mechanism that has a potential inequity, model the decision making process, and evaluate/audit this model using parity measures and frameworks of distributive justice. 
								I hope that this paper can teach data scientists or those interested in the field about how ethics and fairness come into play in data science and the algorithms us data scientists create. 
							</p>
							<p>The New York City Civilian Complaint Review Board (CCRB), the system in this context, is an agency independent from the New York Police Department that investigates complaints against NYPD officers regarding allegations of excessive or unnecessary force, abuse of authority, discourtesy, or offensive language. 
								Throughout the investigation process, the review board may obtain further evidence from the NYPD (e.g., body camera footage) and conduct interviews of anyone involved to use alongside any details the complainant submitted in their original complaint. 
								Specific complainant/victim attributes collected include age, gender, and ethnicity. The complainant may also provide details on the officers's sex, race, and physical appearance.
							</p>
							<p>The potential inequity I investigated involves the "disposition" of a given complaint, or the ruling the CCRB determines. 
								A substantiated complaint is one for which the alleged conduct was found to have happened and violated NYPD rules, potentially leading to punishment or repercussions for the accused officer.
								 The data shows that complaints submitted by Black complainants were less often substantiated than non-Black complainants. 
								 This discrepancy was the launching pad for my investigation of this inequity and audit of the CCRB. 
							</p>

							<h2>Tools Used</h2>

							<span class="center"><img src="images/tools_used_pic.png" alt="" width="50%"/></span>
                            <style>
                                img {
                                  display: block;
                                  margin-left: auto;
                                  margin-right: auto;
                                }
                            </style>

							<ul>
								<li>Python</li>
								<li>Jupyter Notebooks</li>
								<li>Scikit Learn for Modeling</li>
								<li>Pandas for Data Cleaning, Exploration, etc.</li>
								<li>NumPy for Data Cleaning, Exploration, etc.</li>
								<li>Matplotlib for Data Visualization</li>
							</ul>

							<h2>The Data</h2>
							<p>
								The data originally comes from <a href="https://www.propublica.org/datastore/dataset/civilian-complaints-against-new-york-city-police-officers">ProPublica</a> and contains information regarding complaints made starting in 1985 up to 2020. 
								The model uses data starting in 2000 because key demographic features like complainant ethnicity were not tracked before then. 
								All complaints include the type of complaint made, the precinct in which the alleged action took place, demographics on the complainant, and demographics on the accused officer. 
								See <a href="https://github.com/jacquelinekclee/algorithmic-audit-nyc-ccrb/blob/ca06036fecf6efa016e9cd8de1fe9637768bffa5/allegations.csv">allegations.csv</a> and <a href="https://github.com/jacquelinekclee/algorithmic-audit-nyc-ccrb/blob/ca06036fecf6efa016e9cd8de1fe9637768bffa5/allegations_cleaned.csv">allegations_cleaned.csv</a>.
							</p>

							<h3>Additional Data</h3>
							<p>
								Borough was not a column initially included in the dataset, so the precincts were mapped to their apporpriate boroughs using data pulled from the <a href="https://www1.nyc.gov/site/nypd/bureaus/patrol/precincts-landing.page">NYPD's website</a>.
								See <a href="https://github.com/jacquelinekclee/algorithmic-audit-nyc-ccrb/blob/ca06036fecf6efa016e9cd8de1fe9637768bffa5/precinct_borough.csv">precinct_boroughs.csv</a>.
								In order to understand the different categories of complaints and the potential consequences an officer may face, I referenced the <a href = "https://www1.nyc.gov/assets/ccrb/downloads/pdf/about_pdf/Title38-A_20210526.pdf">CCRB's rules</a>. This information was used in feature engineering.  
								In the first, investigatory paper, data on arrests in NYC and stop, question, and frisk patterns were investigated. Please visit <a href = "https://data.cityofnewyork.us/Public-Safety/NYPD-Arrests-Data-Historic-/8h9b-rp9u">this link </a> for the arrests data and 
								<a href = "https://data.cityofnewyork.us/Public-Safety/The-Stop-Question-and-Frisk-Data/ftxv-d5ix">this link</a> for the stop, question, and frisk data. 
							</p>

							<h2>The Logistic Regression Model</h2>
							<p>
								A simple logistic regression model with with L2 regularization was used to model the CCRB's decision process. 
								To train the model, a simple 75%-25% train-test split was used. 
								To combat the class imbalance present (only about 25% of complaints were deemed substantiated), the <code>class_weight</code> hyperparameter, which assigns a weight to each class that the model uses for penalizing, was used. 
								In order to determine the proper decision thereshold, different utility functions were compared, ultimately leading to a threshold of 0.527 instead of the default 0.5. 
								This means that anything that the model classifies points as substantiated if the resulting regression prediction is at least 0.527. See the paper for more details. 

							</p>
							<h3>Features</h3>
							<p>
								The features used in the model are:
							</p>
							<ul>
								<li><code>contact_reason</code> (or text indicating why the officer approached the civilian)</li>
								<li><code>mos_ethinicity</code> (officer's ethnicity), rank_incident (officer's rank at time of incident)</li>
								<li><code>mos_gender</code> (officer's gender)</li>
								<li><code>complainant_gender</code> (omplainant's gender)</li>
								<li><code>mos_age_incident</code> (oofficer's age at time of incident)</li>
								<li><code>complainant_age_incident</code> (complainant's age at time of incident)</li>
								<li><code>borough</code> (the borough in which the incident took place)</li>
								<li><code>black</code> (whether the complainant is Black)</li>
								<li><code>allegation</code> (brief description of the allegation)</li>
								<li><code>fado_type</code> (type of complaint)</li>
								<li>time/date related features (`month_received`, `year_received`, `month_closed`, and `year_closed`)/li>
							</ul>

							<p>
								All categorical features except allegation and fado_type were one-hot encoded while the exceptions were ordinal encoded. The numerical features were scaled. 
							</p>

							<h3>Evaluation Metrics</h3>
							<p>
								The class imbalance makes accuracy ill-suited for this model, so the F1 score was used instead. The test performance metrics for all groups is as follows:
								<ul>
									<li>Accuracy Score: 0.623882406425216</li>
									<li>Recall score: 0.526413921690491</li>
									<li>Precision score: 0.3299571484222828</li>
									<li>F1 score: 0.4056513409961685</li>
							</p>

							<h2>Overview of Parity Measures and Fairness Results</h2>
							<p>
								For a breakdown of different parity measures and fairness in machine learning, take a look at <a href = "https://developers.google.com/machine-learning/glossary/fairness">Google's Machine Learning Glossary: Fairness</a>.
								With the original model, a singular threshold was used. Under this model, both demographic parity and equalized odds were not satisfied, but predictive value parity was met. The original model substantiated complaints from Black civilians far less often than it did for non-Black complainants. The violation in equalized odds means the model gave more complaints submitted by non-Black complainants the “benefit of the doubt” and classified more CCRB-unsubstantiated complaints as substantiated than for Black complainants.
								To try and improve these metrics for fairness, 2 different threshold tests were conducted to find better thresholds based on groups (complainant ethnicity in this case). Firstly, the thresholds that maximize utility for the individual group were used. These thresholds satisfied demographic parity and equalized odds, but not predictive value parity. Secondly, the thresholds that satisfy the 3 parity measures (demographic parity, equalized odds, and predictive value parity) were found using the training data and then tested with a separate dataset. See the paper for a more in depth breakdown on how these tests were conducted.
								Depending on what is most important to the decision-making body (CCRB), different threshold(s) would be chosen. Maximizing utility overall enforces equality for all complainants, while maximizing utility for each group is more equitable. Satisfying demographic parity ensures that substantiation doesn’t depend on complainant ethnicity. Equality of odds would focus on ensuring that the chance of obtaining the benefit of substantiation is equal across groups, while predictive value parity focuses on ensuring deserving complainants receive substantiation and underserving complainants don't. The table below demonstrates different group thresholds that could be used, depending on the goal (maximizing utility or enforcing a parity measure).
							</p>

							<table>
								<tr>
								  <th>Threshold for Black Complainants</th>
								  <th>Threshold for non-Black Complainants</th> 
								  <th>Test</th>
								  <th>Demographic Parity</th>
								  <th>Equality of Odds</th>
								  <th>Predictive Value Parity</th>
								</tr>
								<tr>
								  <td>0.527s</td>
								  <td>0.527</td> 
								  <td>Max utility overall</td>
								  <td>Not satisfied</td>
								  <td>Not satisfied</td>
								  <td>Satisfied</td>
								</tr>
								<tr>
									<td>0.522</td>
								  <td>0.546</td> 
								  <td>Max utility per group</td>
								  <td>Satisfied</td>
								  <td>Not satisfied</td>
								  <td>Not atisfied</td>
								</tr>
								<tr>
									<td>0.522</td>
								  <td>0.541</td> 
								  <td>Enforce equality of odds</td>
								  <td>N/A</td>
								  <td>Strictly satisfied</td>
								  <td>N/A</td>
								</tr>
								<tr>
									<td>0.522</td>
								  <td>0.535</td> 
								  <td>Enforce predictive value parityl</td>
								  <td>N/A</td>
								  <td>N/A</td>
								  <td>Not atisfied</td>
								  </tr>

							  </table>

							  <h2>Conclusion</h2>
							  <p>
								Hopefully this paper shows that often times, an algorithm or model may (unintentionally) be unfair or inequitable if such parity measures or metrics of fairness are not considered. As for this specific example of the CCRB, the model missses out on lots of data perhaps gathered in the investigation process, but still demonstrates evidence of inequities or unfairness. The bottom line is that any model or algorithm absolutely should consider its fairness! 

							  </p>

                        </article>
						<!-- Results -->
							<article id="positions">
								<h1 id="nba-players-position-classifier">NBA Players Position Classifier</h1>
<p><img src="images/positionless-nba-2.png" alt="banner"></p>
<p><a href="https://www.cbssports.com/nba/news/power-guard-point-center-the-nbas-positional-misfits-are-dismantling-an-antiquated-system/">SOURCE</a></p>
<h1 id="links">Links</h1>
<ul>
<li><a href="https://jacquelinekclee.github.io/nba-players-position-classifier/">Website</a></li>
<li><a href="https://github.com/jacquelinekclee/nba-players-position-classifier">Repository (with all relevant files/data)</a></li>
</ul>
<h1 id="table-of-contents">Table of contents</h1>
<ul>
<li><a href="#background">Background</a></li>
<li><a href="#the-statistics">The Statistics</a></li>
<li><a href="#statistics-source">Statistics Source</a></li>
<li><a href="#the-methodology">The Methodology</a><ul>
<li><a href="#training">Training</a></li>
<li><a href="#final-model">Final Model</a></li>
</ul>
</li>
<li><a href="#usage">Usage</a></li>
<li><a href="#findings">Findings</a></li>
<li><a href="#source-file">Source File</a></li>
<li><a href="#legality">Legality</a></li>
</ul>
<h2 id="background">Background</h2>
<p>As someone who has been playing basketball since the second grade and has been a Warriors fan since birth, the NBA and basketball in general have always held a special place in my heart. As time goes on, statistics and analytics have played an increasingly larger role in the world of basketball. With this project, and my <a href="https://jacquelinekclee.github.io/nba-all-stars-classifier.github.io/">NBA All Stars Classifier</a>, I wanted to use my love of basketball in developing and praciticing new Data Science skills.</p>
<p>As basketball players have gotten more skilled and talented and as the game itself has revolutionized, the notion of positions increasingly becomes a dated aspect of the game. The commissioner of the NBA, Adam Silver, acknowledged that the NBA <a href="https://www.nba.com/news/nba-commissioner-adam-silver-discusses-leagues-positionless-basketball-at-annual-finals-press-conference">&quot;has moved increasingly to positionless basketball&quot;</a> when discussing the possibility of removing positions from the All-NBA decision process, which honors the best players in the league. </p>
<p>With this project, I hope to understand basketball positions using statistics and machine learning. If an ML model can predict a player&#39;s position based on his stats, then maybe this player doesn&#39;t play positionless basketball and adheres to his traditional role as a guard/forward/center. If a model gets it wrong, then maybe the player has a unique play style that doesn&#39;t conform to the historic statistics of players in his positions before him. </p>
<p>Keep reading to learn more about the data used, the approach I took to building this classifier, and the cool findings the model yielded!</p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="the-statistics">The Statistics</h2>
<p>The NBA tracks almost 50 different statistics for every player in the league. Many statistics are often unknown to most basketball fans, so using only the common statistics will make the most sense for everyone. 
Here are some basic definitions of the statistics I will be using in my classifier:</p>
<ul>
<li>True shooting percentage (TS%): a metric that demonstrates how efficiently a player shoots the ball. Takes into consideration field goals, 3-pointers, and free throws (unlike other metrics like field goal percentage).</li>
<li>Rebounds per game (RPG): a metric that shows how many total rebounds (both offensive and defensive) a player averages per game. </li>
<li>Assists per game (APG): a metric that shows how many total assists a player averages per game.</li>
<li>Points per game (PPG): a metric that shows how many total points a player averages per game.</li>
<li>Blocks per game (BPG): a metric that shows how many total blocks a player averages per game.</li>
<li>Steals per game (SPG): a metric that shows how many total steals a player averages per game.</li>
</ul>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="statistics-source">Statistics Source</h2>
<p>The training data comes from <a href="https://www.kaggle.com/drgilermo/nba-players-stats?select=Seasons_Stats.csv">Kaggle</a>. The test data come from <a href="https://www.basketball-reference.com/">Basketball Reference</a>:</p>
<ul>
<li><a href="https://www.basketball-reference.com/leagues/NBA_2019_per_game.html">2018-19 Data</a></li>
<li><a href="https://www.basketball-reference.com/leagues/NBA_2021_per_game.html">2020-21 Data</a></li>
<li><a href="https://www.basketball-reference.com/leagues/NBA_2022_per_game.html">2021-22 Data</a></li>
</ul>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="usage">Usage</h2>
<p>Please refer to the <a href="https://nbviewer.org/github/jacquelinekclee/nba-players-position-classifier/blob/0d3b4b07abce345b5b50566b95ac793e7ba10c5d/nba_positions_classifier.ipynb">Jupyter Notebook Viewer</a> or the <a href="https://github.com/jacquelinekclee/nba-players-position-classifier/blob/0d3b4b07abce345b5b50566b95ac793e7ba10c5d/nba_positions_classifier.ipynb">.ipynb file</a> to view all the code for the classifier. The notebook with all the data cleaning can be seen <a href="https://github.com/jacquelinekclee/nba-players-position-classifier/blob/0d3b4b07abce345b5b50566b95ac793e7ba10c5d/nba_players_data_cleaning.ipynb">here</a>. </p>
<p>The <a href="#source-file">source file</a> contains all the functions used to clean/manipulate the data and DataFrames.</p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="the-methodology">The Methodology</h2>
<p>In the initial data cleaning process, the players&#39; positions were simplified to include 5 classes: </p>
<table>
<thead>
<tr>
<th style="text-align:left">Position</th>
<th style="text-align:right">Proportion in Training Data</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Forward</td>
<td style="text-align:right">0.399</td>
</tr>
<tr>
<td style="text-align:left">Guard</td>
<td style="text-align:right">0.396</td>
</tr>
<tr>
<td style="text-align:left">Center</td>
<td style="text-align:right">0.199</td>
</tr>
<tr>
<td style="text-align:left">Guard/Forward</td>
<td style="text-align:right">0.003</td>
</tr>
<tr>
<td style="text-align:left">Forward/Center</td>
<td style="text-align:right">0.003</td>
</tr>
</tbody>
</table>
<p>Notice that forwards and guards make up nearly 80% of the datasest, with centers making just under 20% and the hybrid positions making up hardly 1% altogether. Since this is a multiclass problem with some class imbalance, I wanted to test different models. Another consideration was the effect of including Year as a feature. Theoretically, if the way a player of a given position hasn&#39;t changed over time, then a classifier without year should perform better (or differently) than a classifier with year as a feature. </p>
<p>I tried both random forest modesl and XGBoost models. I went with random forests as a better alternative to decision trees in that random forests are more robust to overfitting. I also chose to explore XGBoost classifiers as they might work better for the class imbalance. In total, 4 different models were originally trained: 2 random forests (one with year as a featuere and one without) and 2 XGBoost classifiers (one with year as a feature and one without). The features for both models were as follows:</p>
<ul>
<li>TS%: true shooting percentage</li>
<li>RPG: rebounds per game</li>
<li>APG: assists per game</li>
<li>PPG: points per game</li>
<li>BPG: blocks per game</li>
<li>SPG: steals per game</li>
<li>Year: year of that season (e.g, rows from the 1980-1981 season has 1981 as its year)</li>
<li>All Star: whether that player was an All Star that season</li>
<li>MVP: whether that player was the MVP that season</li>
</ul>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="training">Training</h2>
<p>Using Scikit&#39;s <code>GridSearchCV</code>, I tested out several combinations of different hyperparameters. The training times for both models were extremely <em>long</em>. See below for the paramters tested for each type of model:</p>
<p>Parameters tested for random forests:
<code>{&#39;n_estimators&#39;: [300,500,700], &#39;max_features&#39;: [&#39;sqrt&#39;, &#39;log2&#39;], &#39;max_depth&#39; : [5,10,15,20,25,None], &#39;criterion&#39; :[&#39;gini&#39;, &#39;entropy&#39;], &#39;random_state&#39; : [18]}</code></p>
<p>Parameters tested for XGBoost classifiers:
<code>{&#39;max_depth&#39;: [3,6,10], &#39;learning_rate&#39;: [0.01, 0.05, 0.1], &#39;n_estimators&#39;: [100, 500, 1000], &#39;colsample_bytree&#39;: [0.3, 0.7]}</code></p>
<p>Given that this a multiclass classification problem, I found that accuracy was the most straightforward evaluation metric. Additionally, I looked at the proportion of players for a given position that were misclassified. For example, if 10 out of 40 centers in the test data set were <em>not</em> classified as centers by the model, then the proportion would be 0.25. See below for the results found with the 2018-19 season as the test set:</p>
<table>
<thead>
<tr>
<th style="text-align:left">model</th>
<th style="text-align:right">test accuracy</th>
<th style="text-align:right">prop wrong for centers</th>
<th style="text-align:right">prop wrong for forwards</th>
<th style="text-align:right">prop wrong for guards</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">random forest without year</td>
<td style="text-align:right">0.390</td>
<td style="text-align:right">0.48</td>
<td style="text-align:right">0.19</td>
<td style="text-align:right">0.26</td>
</tr>
<tr>
<td style="text-align:left">random forest with year</td>
<td style="text-align:right">0.392</td>
<td style="text-align:right">0.47</td>
<td style="text-align:right">0.19</td>
<td style="text-align:right">0.23</td>
</tr>
<tr>
<td style="text-align:left">XGBoost without year</td>
<td style="text-align:right">0.378</td>
<td style="text-align:right">0.53</td>
<td style="text-align:right">0.2</td>
<td style="text-align:right">0.27</td>
</tr>
<tr>
<td style="text-align:left">XGBoost with year</td>
<td style="text-align:right">0.390</td>
<td style="text-align:right">0.55</td>
<td style="text-align:right">0.16</td>
<td style="text-align:right">0.25</td>
</tr>
</tbody>
</table>
<p>Both types of model performed better when year was included in the feature set, with year boosting accuracy more for the XGBoost models than the random forests. What stuck out to me most was how much better the random forests were at classifying the minority class, centers. </p>
<p>Additionally, the 2 types of classifiers found different features to be more important. The Random Forest classifiers thought RBG (rebounds per game) were more important than BPG (blocks per game), while the XGBoost classifiers didn&#39;t. Both classifiers had similar levels of feature importance for APG (assists per game) and PPG (points per game). See the notebook for feature importances. </p>
<p>Some pitfalls of both classifiers include: </p>
<ul>
<li>Neither classifier was able to classify the hybrid positions, GF and FC, correctly. This is likely because only about 0.006 of the training data have these hybrid positions. </li>
<li>Both the All Star and MVP features had 0 importance for all 4 models tested. Including irrelevant features could make cost (e.g., runtime) unnecessarily high. </li>
<li>Although XGBoost was used to try and combat the class imbalance (around 2x guards and forwards than centers), XGBoost did <em>worse</em> and classifying centers than Random Forest did. </li>
</ul>
<p>In effort to create a better performing classifier, a new position column will be created. Hopefully making this problem only 3 classes instead of 5 will yield a better classifier. Also, MVP and All Star will be removed from the feature list. It seems that the year feature is particularly useful for classifying guards. Lastly, although XGBoost yielded a slightly higher accuracy, it classified centers much worse than the random forest (which was unexpected). Since the XGBoost didn&#39;t provide the expected benefits and its training time is much slower, Random Forest will be used going forward. </p>
<h2 id="final-model">Final Model</h2>
<p>Based on the findings above, I went with a Random Forest model with TS%, RPG, APG, PPG, BPG, SPG, and Year as features. See below for the feature importances and test accuracies:</p>
<table>
<thead>
<tr>
<th style="text-align:left">Feature</th>
<th style="text-align:right">Importance</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">RPG</td>
<td style="text-align:right">0.254</td>
</tr>
<tr>
<td style="text-align:left">APG</td>
<td style="text-align:right">0.251</td>
</tr>
<tr>
<td style="text-align:left">BPG</td>
<td style="text-align:right">0.233</td>
</tr>
<tr>
<td style="text-align:left">SPG</td>
<td style="text-align:right">0.116</td>
</tr>
<tr>
<td style="text-align:left">PPG</td>
<td style="text-align:right">0.077</td>
</tr>
<tr>
<td style="text-align:left">TS%</td>
<td style="text-align:right">0.037</td>
</tr>
<tr>
<td style="text-align:left">Year</td>
<td style="text-align:right">0.031</td>
</tr>
</tbody>
</table>
<table>
<thead>
<tr>
<th style="text-align:left">season</th>
<th style="text-align:right">test accuracy</th>
<th style="text-align:right">prop wrong for centers</th>
<th style="text-align:right">prop wrong for forwards</th>
<th style="text-align:right">prop wrong for guards</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">2018-19</td>
<td style="text-align:right">0.736</td>
<td style="text-align:right">0.47</td>
<td style="text-align:right">0.19</td>
<td style="text-align:right">0.24</td>
</tr>
<tr>
<td style="text-align:left">2020-21</td>
<td style="text-align:right">0.715</td>
<td style="text-align:right">0.46</td>
<td style="text-align:right">0.22</td>
<td style="text-align:right">0.27</td>
</tr>
<tr>
<td style="text-align:left">2021-22</td>
<td style="text-align:right">0.704</td>
<td style="text-align:right">0.54</td>
<td style="text-align:right">0.19</td>
<td style="text-align:right">0.27</td>
</tr>
</tbody>
</table>
<p>Clearly, this model performed much better than the 1st round. However, it started performing worse for the more recent seasons. This may be some indication of a shift coming in basketball, where players&#39; statistics and general playstyles don&#39;t reflect the typical notions of positions in seasons prior. </p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="findings">Findings</h2>
<p>Draymond Green, Ben Simmons, Giannis Antetokounmpo, LeBron James, Kevin Durant, Nikola Jokić, and Jayson Tatum are some consensus &quot;positionless&quot; NBA players (see this <a href="&#39;https://bleacherreport.com/articles/2627364-5-unique-nba-players-who-dont-fit-in-a-category&#39;">CBS article</a> and this <a href="&#39;https://bleacherreport.com/articles/2627364-5-unique-nba-players-who-dont-fit-in-a-category&#39;">Blearcher Report article</a>). One might expect the classifier to predict these players&#39; posititions <em>incorrectly</em> if they are truly &quot;positionless.&quot; As with all things basketball, several things transcend the stat sheet, but hopefully these results provide some interesting insights! The table below shows the correct position (Pos) and the model&#39;s prediction (pos_pred) for these &quot;positionless&quot; players:</p>
<table>
<thead>
<tr>
<th style="text-align:left">Player</th>
<th style="text-align:left">Pos_2019</th>
<th style="text-align:left">pos_pred_2019</th>
<th style="text-align:left">Pos_2021</th>
<th style="text-align:left">pos_pred_2021</th>
<th style="text-align:left">Pos</th>
<th style="text-align:left">pos_pred</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">Giannis Antetokounmpo</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
</tr>
<tr>
<td style="text-align:left">Kevin Durant</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
</tr>
<tr>
<td style="text-align:left">Draymond Green</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">G</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
</tr>
<tr>
<td style="text-align:left">LeBron James</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">G</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
</tr>
<tr>
<td style="text-align:left">Nikola Jokić</td>
<td style="text-align:left">C</td>
<td style="text-align:left">F</td>
<td style="text-align:left">C</td>
<td style="text-align:left">F</td>
<td style="text-align:left">C</td>
<td style="text-align:left">F</td>
</tr>
<tr>
<td style="text-align:left">Jayson Tatum</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
<td style="text-align:left">F</td>
</tr>
</tbody>
</table>
<p>Giannis Antetokounmpo, Kevin Durant, and Jayson Tatum were always correctly classified as forwards for the 3 seasons used as test data. This may be because forwards were the most common position in the training data, so the classifier knows forwards particularly well. </p>
<p>Basketball Reference has LeBron James listed as having played both the forward and guard positions. In the 2020-21 season, where James was listed primarily as a guard, the classifier predicted him incorrectly to be a forward. In the eyes of the classifier, it seems that James presents as a forward more than a guard.</p>
<p>In the 2020-21 season, Draymond Green was listed as a forward, but misclassified as a guard. Green had to step up that season considering Klay Thompson&#39;s absence that season and the fact that other guards like Jordan Poole (playing only his 3rd year professionaly after some time in the G-League) and Gary Payton II (who hardly played at all) were early in their development. </p>
<p>Hopefully some of these insights were interesting! Please feel free to explore the Python notebooks on your own!</p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="source-file">Source File</h2>
<ul>
<li><a href="https://github.com/jacquelinekclee/nba-players-position-classifier/blob/0d3b4b07abce345b5b50566b95ac793e7ba10c5d/nba_players_classification.py">nba_players_classification.py</a><ul>
<li>Has all the functions used for mainly the data cleaning.</li>
</ul>
</li>
</ul>
<h2 id="legality">Legality</h2>
<p>This personal project was made for the sole intent of applying my skills in Python thus far and as a way to learn new ones. It is intended for non-commercial uses only.</p>
<p><a href="#table-of-contents">(Back to top)</a></p>

								
						</article>

						<!-- Contact -->
							<article id="allstars">
								<h1 id="predicting-nba-all-stars">Predicting NBA All Stars</h1>
<p><img src="images/all_stars_2022-2.png" alt="banner"></p>
<p><a href="https://www.nba.com/news/best-portraits-2022-nba-all-star">SOURCE</a></p>
<h1 id="links">Links</h1>
<ul>
<li><a href="https://jacquelinekclee.github.io/nba-all-stars-classifier.github.io/">Website</a></li>
<li><a href="https://github.com/jacquelinekclee/nba-all-stars-classifier.github.io">Repository (with all relevant files/data)</a></li>
</ul>
<h1 id="table-of-contents">Table of contents</h1>
<ul>
<li><a href="#background">Background</a></li>
<li><a href="#the-statistics">The Statistics</a></li>
<li><a href="#statistics-source">Statistics Source</a></li>
<li><a href="#the-methodology">The Methodology</a><ul>
<li><a href="#training">Training</a></li>
</ul>
</li>
<li><a href="#usage">Usage</a></li>
<li><a href="#findings">Findings</a></li>
<li><a href="#the-results">The Results</a></li>
<li><a href="#source-file">Source File</a></li>
<li><a href="#legality">Legality</a></li>
</ul>
<h2 id="background">Background</h2>
<p>As someone who has been playing basketball since the second grade and has been a Warriors fan since birth, the NBA and basketball in general have always held a special place in my heart. As time goes on, statistics and analytics have played an increasingly larger role in the world of basketball. With this project, and my <a href="https://jacquelinekclee.github.io/nba-players-position-classifier.github.io/">NBA Player Position Classifier</a>, I wanted to use my love of basketball in developing and praciticing new Data Science skills.</p>
<p>This classifier, specifically a K-Nearest Neighbors Classifier, uses statistics from nearly 19,000 players&#39; seasons from 1980-2017. I will then test my classifier using statistics from the 2018-19 season, the 2020-21 season (skipping the season interrupted by the pandemic), and the most recent season, 2021-22. Given that all star voting involves non-expert (fan) voting and some level of subjectivity, hopefully the results will help reveal which players&#39; All Star designation(s) match the data, which players were overlooked, and which players were perhaps overrated. </p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="the-statistics">The Statistics</h2>
<p>The NBA tracks almost 50 different statistics for every player in the league. Many statistics are often unknown to most basketball fans, so using only the common statistics will make the most sense for everyone. 
Here are some basic definitions of the statistics I will be using in my classifier:</p>
<ul>
<li>True shooting percentage (TS%): a metric that demonstrates how efficiently a player shoots the ball. Takes into consideration field goals, 3-pointers, and free throws (unlike other metrics like field goal percentage).</li>
<li>Rebounds per game (RPG): a metric that shows how many total rebounds (both offensive and defensive) a player averages per game. </li>
<li>Assists per game (APG): a metric that shows how many total assists a player averages per game.</li>
<li>Points per game (PPG): a metric that shows how many total points a player averages per game.</li>
<li>Blocks per game (BPG): a metric that shows how many total blocks a player averages per game.</li>
<li>Steals per game (SPG): a metric that shows how many total steals a player averages per game.</li>
</ul>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="statistics-source">Statistics Source</h2>
<p>The training data comes from <a href="https://www.kaggle.com/drgilermo/nba-players-stats?select=Seasons_Stats.csv">Kaggle</a>. The test data come from <a href="https://www.basketball-reference.com/">Basketball Reference</a>:</p>
<ul>
<li><a href="https://www.basketball-reference.com/leagues/NBA_2019_per_game.html">2018-19 Data</a></li>
<li><a href="https://www.basketball-reference.com/leagues/NBA_2021_per_game.html">2020-21 Data</a></li>
<li><a href="https://www.basketball-reference.com/leagues/NBA_2022_per_game.html">2021-22 Data</a></li>
</ul>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="usage">Usage</h2>
<p>Please refer to the <a href="https://nbviewer.org/github/jacquelinekclee/nba-all-stars-classifier.github.io/blob/3779271415ee1cf80baaaf659555743dc93966e9/nba_all_stars_classifier.ipynb">Jupyter Notebook Viewer</a> or the <a href="https://github.com/jacquelinekclee/nba-all-stars-classifier.github.io/blob/3779271415ee1cf80baaaf659555743dc93966e9/nba_all_stars_classifier.ipynb">.ipynb file</a> to view all the code for the classifier. The notebook with all the data cleaning can be seen <a href="https://github.com/jacquelinekclee/nba-all-stars-classifier.github.io/blob/3779271415ee1cf80baaaf659555743dc93966e9/nba_players_data_cleaning.ipynb">here</a>. </p>
<p>The <a href="#source-file">source file</a> contains all the functions used to clean/manipulate the data and DataFrames.</p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="the-methodology">The Methodology</h2>
<p>Since only about 5% of players in a given season are designated All Stars, a classifier that does well predicting the minority class is needed. Additionally, instead of using accuracy as the evaluation metric, recall was chosen instead given my interest in capturing all the All Star players in each season. In <a href="https://towardsdatascience.com/classifying-rare-events-using-five-machine-learning-techniques-fab464573233">this Medium article</a>, by Leihua Ye, PhD found that K-Nearest Neighbors performed best for prediciting rare events, especially when looking at ROC Curves. Given these findings, KNN&#39;s lack of of training time, and its simplicity, KNN was chosen. </p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="training">Training</h2>
<p>The main hyperparamter in KNN is of course the number of neighbors <code>k</code>. Several sources indicate that <code>n ** 2</code>, where $n$ is the number of instances in the sample, is a good heuristic for best <code>k</code>. Other important hyperparameters are <code>weights</code>, or how the nearest neighbors are used in determining the final prediction, and <code>metric</code>, or which distance metric KNN uses. I used Scikit&#39;s <code>GridSearchCV</code> to combine both hyperparameter tuning and training the model with cross validation to determine the final model. See below for the parameters tested and the ultimate model parameters:</p>
<p>Parameters tested:
<code>{&#39;clf__n_neighbors&#39; : [19, 21, 23, 25, 27], &#39;clf__weights&#39; : [&#39;uniform&#39;,&#39;distance&#39;], &#39;clf__metric&#39; : [&#39;minkowski&#39;,&#39;euclidean&#39;,&#39;manhattan&#39;]}</code></p>
<p>Best paramters:
<code>{&#39;clf__metric&#39;: &#39;minkowski&#39;, &#39;clf__n_neighbors&#39;: 19, &#39;clf__weights&#39;: &#39;distance&#39;}</code></p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="findings">Findings</h2>
<p>Below is a table summarizing the recall scores:</p>
<table>
<thead>
<tr>
<th style="text-align:left">Season</th>
<th style="text-align:right">Recall Score</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">2019-2018</td>
<td style="text-align:right">0.615</td>
</tr>
<tr>
<td style="text-align:left">2020-2021</td>
<td style="text-align:right">0.741</td>
</tr>
<tr>
<td style="text-align:left">2021-2022</td>
<td style="text-align:right">0.667</td>
</tr>
</tbody>
</table>
<p>The classifier was able to find a majority of each season&#39;s all stars, performing best for the 2020-21 season. </p>
<h2 id="the-results">The Results</h2>
<p>See below for some discussion on the model&#39;s predictions. See the table linked <a href="/all_star_classifier_summary.csv">here</a> to see a full summary of the 3 NBA seasons used in testing and the results for each player. </p>
<h3 id="-properly-rated-all-stars-the-true-positives">&quot;Properly Rated&quot; All Stars: The True Positives</h3>
<p>There were only 6 players who were voted as All Stars for all 3 seasons (2018-19, 2020-21, and 2021-22) <em>and</em> were deemed &quot;properly rated&quot; for all 3 seasons. In this case, &quot;properly rated&quot; means that the all star voting seemed to match the data and the KNN model&#39;s findings.</p>
<ul>
<li>Giannis Antetokounmpo</li>
<li>James Harden</li>
<li>Joel Embiid</li>
<li>Kevin Durant</li>
<li>LeBron James</li>
<li>Stephen Curry</li>
</ul>
<h3 id="-overrated-all-stars-the-false-negatives">&quot;Overrated&quot; All Stars: The False Negatives</h3>
<p>The &quot;overrated&quot; players are instances where the classifier predicted a player <em>wasn&#39;t</em> an All Star when in reality they were. These cases could include players that perhaps contribute in ways that don&#39;t show up on the stat sheet or players that a particular fan favorites. For instance, in the 2018-19 season, future hall-of-famers and NBA champions Dirk Nowitzki and Dwyane Wade were voted as All Stars, but the classifier thought differently. That season was both Nowitzki and Wade&#39;s last season in the NBA, so while their stats maybe weren&#39;t up to par, their legendary careers earned them the designation. </p>
<p>For 2 of the 3 seasons used in testing, Ben Simmons (2018-19 and 2020-21), Khris Middleton (2018-19 and 2021-22), Nikola Vučević (2018-19 and 2020-21), and Rudy Gobert (2020-21 and 2021-22) all fell under the &quot;overrated&quot; category. Middleton might not have the opportunity to shine in the stats playing alongside generational talent Giannis Antetokounmpo, thus resulting in a false negative. The same could be said about Ben Simmons who played with Joel Embiid, but his recent (lack of) play may make fans agree with the &quot;overrated&quot; designation. </p>
<p>Another interesting case of &quot;overrated&quot; all stars is Nikola Jokić. The model deemed him to be &quot;overrated&quot; in 2018-19, but in the 2 previous seasons (during which he got consecutive MVP honors), the model correctly predicted him as an All Star. </p>
<h3 id="-underrated-players-the-false-positives">&quot;Underrated&quot; Players: The False Positives</h3>
<p>The &quot;underrated&quot; players are those that the classifier predicted to be all stars, but weren&#39;t voted as all stars in reality. Perhaps the stats of such a player were exceptional, but other aspects like their winning percentages weren&#39;t up to par. See below for the players from the 2018-19, 2020-21, and 2021-22 seasons that were deemed underrated and were never selected as an All Star in any of the 3 seasons:</p>
<ul>
<li>Brandon Ingram (2020-21)</li>
<li>CJ McCollum (2020-21)</li>
<li>John Wall (2018-19)</li>
<li>Jrue Holiday (2019-19)</li>
<li>Pascal Siakam (2021-22)</li>
<li>Shai Gilgeous-Alexander (2020-21, 2021-22)</li>
</ul>
<p>One interesting player here is Pascal Siakam, who was voted an All Star in the 2019-2020, the season after he won a championship. Siakam was perhaps overlooked by fans and/or the media playing in Toronto (as opposed to in the U.S. or a larger market team). For 2 seasons in a row, young guard Shai Gilgeous-Alexander was &quot;underrated&quot; in the eyes of the model. His team, the OKC Thunder, had a terrible record this past season and finished in 14th place in the Western Conference. This lack of winning, and the fact that OKC is a smaller market, may explain why Gilgeous-Alexander was overlooked in all star voting.</p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="source-file">Source File</h2>
<ul>
<li><a href="https://github.com/jacquelinekclee/nba-all-stars-classifier.github.io/blob/a6dd72fb58304c2a2c4c9125883913b60662731f/nba_players_classification.py">nba_players_classification.py</a><ul>
<li>Has all the functions used for mainly the data cleaning.</li>
</ul>
</li>
</ul>
<h2 id="legality">Legality</h2>
<p>This personal project was made for the sole intent of applying my skills in Python thus far and as a way to learn new ones. It is intended for non-commercial uses only.</p>
<p><a href="#table-of-contents">(Back to top)</a></p>

							</article>
				<article id = "hiphop">
						<h1 id="has-hip-hop-gotten-worse-web-scraping-and-nlp-project">Has Hip-Hop Gotten Worse? - Web Scraping and NLP Project</h1>
<p><img src="images/rappers-2.JPG" alt="banner"></p>
<p><a href="https://www.behance.net/gallery/32828663/Complex-Best-Rapper-Alive-since-1979">SOURCE</a></p>
<h1 id="links">Links</h1>
<ul>
<li><a href="https://jacquelinekclee.github.io/hiphop_nlp_webscrape/">Website</a></li>
<li><a href="https://github.com/jacquelinekclee/hiphop_nlp_webscrape/">Repository (with all relevant files/data)</a></li>
</ul>
<h1 id="table-of-contents">Table of contents</h1>
<ul>
<li><a href="#background">Background</a></li>
<li><a href="#song-selection">Song Selection</a></li>
<li><a href="#lyrics-source">Lyrics Source</a></li>
<li><a href="#metrics">Metrics</a></li>
<li><a href="#goal">Goal</a></li>
<li><a href="#usage">Usage</a></li>
<li><a href="#findings">Findings</a></li>
<li><a href="#legality">Legality</a></li>
<li><a href="#source-files">Source Files</a></li>
</ul>
<h2 id="background">Background</h2>
<p>Hip-hop/rap music was founded in the 1970&#39;s and became widespread during the 80&#39;s, kicking off the decade-long era known as the &quot;golden age&quot; of hip-hop <a href="https://www.npr.org/templates/story/story.php?storyId=7550286#:~:text=Rap%20as%20a%20genre%20began,generally%20interacting%20with%20the%20audience.">(NPR)</a>.</p>
<p>Today, hip-hop/rap is music&#39;s most popular and commercially successful genre. Every region has its own style of rap and numerous musical and cultural trends have defined hip-hop over the years.</p>
<p>Many fans believe that rap music has gotten worse over the years, crediting this decline to the rise of what is called <a href="https://www.cleveland.com/entertainment/2017/06/what_is_mumble_rap_25_essentia.html">mumble rap</a>, a style characterized by artists rapping inchorently and/or melodically and using a variety of ad-libs as opposed to actual lyrics. But, while mumble rap has certainly risen in popularity, does this mean that &quot;good&quot; rap, music filled with clever and meaningful lyrics, has vanished from the genre? </p>
<p>To answer this question, I will be analyzing the lyrics of the best rap song from every year from 1990 to 2020. </p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="song-selection">Song Selection</h2>
<p>Songs from 1990-2003 will be pulled from <strong>Complex article, <a href="https://www.complex.com/music/best-rap-songs-since-1979/">&quot;The Best Rap Song, Every Year Since 1979&quot;</a></strong> and the songs from 2004-2020 will be the winners of the <strong><a href="https://en.wikipedia.org/wiki/Grammy_Award_for_Best_Rap_Song#Recipients">Grammy Award for Best Rap Song</a></strong> (first awarded in 2004).</p>
<ul>
<li>Since many artists have won the Best Rap Song award multiple times (Kanye West, JAY-Z, Kendrick Lamar), this analysis focuses more on whether or not the best of the best rap songs from more current years are just as good as those from the 90&#39;s and early 2000&#39;s rather than finding out if the hip-hop/rap genre as a whole has seen a decline in song quality.</li>
<li>&quot;The Choice Is Yours&quot; by Black Sheep is not on AZLyrics and also not on Spotify, so I will use one of Complex&#39;s honorable mentions, &quot;My Mind Playin&#39; Tricks On Me&quot; by Geto Boys.</li>
<li>Complex&#39;s choice for 2002 (&quot;Lose Yourself&quot; by Eminem) is the same as the 2004 Best Rap Song recipient, so similarly I will use one of Complex&#39;s honorable mentions, &quot;Grindin&quot; by The Clipse.</li>
</ul>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="lyrics-source">Lyrics Source</h2>
<p>The lyrics for each will be scraped from <strong><a href="https://www.azlyrics.com/">AZLyrics</a></strong>. Since these lyrics are user submitted, the formatting of lyrics is variable. This variation is largely in how chorus lyrics are posted. For example, one song may have all the lyrics to the entire chorus typed out each time whereas another may just use &#39;[Chorus]&#39; or &#39;[2x]&#39; to avoid repetition. My hope is that this will not affect the metrics too much, as songs with shorter/less repetitive choruses can indicate a song&#39;s greater substance and lyrical quality.</p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="metrics-">Metrics:</h2>
<ul>
<li>Proportion of unique words to total words, excluding stop words.<ul>
<li>Evaluates the range of vocabulary in a given song.</li>
</ul>
</li>
<li>Proportion of stop words to total words.<ul>
<li>Indicates the substance of a song&#39;s lyrics.</li>
</ul>
</li>
<li>Average number of syllables per bar.<ul>
<li>Examines a rapper&#39;s skill, as it takes more creativity and ingenuity to fit a greater number of syllables into a bar.</li>
</ul>
</li>
<li>Proportion of exact end rhymes and vowel end rhymes (in every two bars or every other bar) to number of bars.<ul>
<li>Also examines a rapper&#39;s lyricism.</li>
<li>Most common rhyme schemes are aabb and abab, so I will only look for these 2.</li>
<li>I will exclude bars using the same words to create the rhyme scheme. In other words, if two bars are &quot;I like greens / She likes greens,&quot; this rhyme will not be counted as the same word is used. This will be done in attempt to accredit songs that more cleverly create rhyme schemes and to avoid inflating this metric for songs with choruses that may be extremely repetitive (e.g., <a href="https://www.azlyrics.com/lyrics/llcoolj/mamasaidknockyouout.html">&quot;Mama Said Knock You Out&quot; by LL Cool J</a>).</li>
<li>The fucntions used to analyze rhymes use the Carnegie Mellon University Pronouncing Dictionary. Therefore, the creativity and accents rapper use to manipulate different rhymes will unfortunately not be detected. Thus, this measure will be analyzed with a grain of salt.</li>
</ul>
</li>
<li>Additionally, I will also be looking at the most common words (excluding stop words) for each song. This measure is much more subjective than the others, but could potentially give insight into a song&#39;s substance.</li>
</ul>
<p><a href="#table-of-contents">(Back to top)</a></p>
<p>Here are some quick definitions of terms used in this project:</p>
<ul>
<li><strong><a href="https://www.lexico.com/en/definition/bar">Bar</a></strong>: One line of lyrics. Detected by line break characters. Typically takes four beats.</li>
<li><strong><a href="https://literarydevices.net/end-rhyme/">End rhymes</a></strong>: Rhymes that occur with the last word/syllables of a bar. Example: &quot;I like greens / She likes beans&quot; (greens and beans, the last word of each bar/line, rhyme).</li>
<li><strong><a href="https://literarydevices.net/exact-rhyme/">Exact rhyme</a></strong>: When the vowel sound and final consonant of two words are phonetically the same, e.g. greens and beans.</li>
<li><strong><a href="https://www.thefreedictionary.com/vowel+rhyme">Vowel rhyme</a></strong>: When the vowel sound of two words are phonetically the same, e.g. green and seem.</li>
<li><strong><a href="https://www.geeksforgeeks.org/removing-stop-words-nltk-python">Stop word</a></strong>: A word that does not contribute much meaning, e.g. the, a, an. Search engines are programmed to ignore these words, and ignoring these words both save processing time and allow us to analyze lyrics more meaningfully.</li>
</ul>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="goal">Goal</h2>
<p>As stated above, this project has some limitations in terms of the consistency of lyric data, the extent to which the packages/tools used can analyze rap lyrics, and the overall subjectivity of this topic. Ultimately, I started this project as a fun way to both explore one of my interests and utilize the skills and technical knowledge I have learned thus far. But, I certainly believe that the results of this project can give insight into how rap music has evolved over the years.</p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="usage">Usage</h2>
<p>Please refer to the <a href="https://nbviewer.jupyter.org/github/jacquelinekclee/hiphop_nlp_webscrape/blob/master/Has%20Hip-Hop%20Gotten%20Worse_.ipynb">Jupyter Notebook viewer</a> to view all the code and visualizations created during this project.</p>
<p>The <a href="#source-files">source files</a> contain all the functions used to web scrape, process the text, and calcualte the metrics used for the project.</p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="findings">Findings</h2>
<p>While all four metrics seemed to decline over the years, <strong>% Unique Rhymes to All Rhymes</strong> (number of unique rhymes / number of all rhymes) proved to be the metric with:</p>
<ul>
<li>The strongest correlation coefficient (-0.52)</li>
<li>Lowest p-value (p = 0.003)</li>
</ul>
<p><img src="images/rhymes_plot.png" alt="scatter"></p>
<p>Even though what qualifies as &quot;good music&quot; will always be subjective, quantifying the quality of lyrics in these songs proved to be insightful. The generally weak relationships between each metric and year indicate that any &quot;decline&quot; in hip-hop/rap music may not be as strong as some would assume. </p>
<p>As mentioned above, hip-hop has become the most popular genre of music. With this ever increasing popularity comes more commercial and lucrative opportunities, and such opportunities are not necessarily conducive to lyrically complex and intricately crafted songs. The genre becoming more commerical and marketable does not mean that there are no lyrically interesting songs being made. But, this trend may contribute to an oversaturated market, where mostly catchy, less intricate songs become popular.</p>
<p>Overall, this project gives evidence that hip-hop as a genre has not seen a dramatic decline. Instead, changing trends in the music industry and how the public consumes media may affect what types of songs become most popular, but not necessarily the skills of all rappers.  </p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="source-files">Source Files</h2>
<ul>
<li><a href="https://github.com/jacquelinekclee/hiphop_nlp_webscrape/blob/master/web_scrape.py">web_scrape.py</a><ul>
<li>Has all the functions used for web scraping and processing the HTML. It also processes the string (lyrics) so it&#39;s ready for analyzing the lyrics.</li>
</ul>
</li>
<li><a href="https://github.com/jacquelinekclee/hiphop_nlp_webscrape/blob/master/lyrics.py">lyrics.py</a><ul>
<li>Used to break down the string of lyrics into bars and words and calculate the word based metrics.</li>
</ul>
</li>
<li><p><a href="https://github.com/jacquelinekclee/hiphop_nlp_webscrape/blob/master/rhyme.py">rhyme.py</a></p>
<ul>
<li>Provides the functions used to calculate the rhyme-based metrics</li>
<li>The contents of this file are adopted from the dandelion package as laid out <a href="https://github.com/DiegoVicen/dandelion">here</a>. Edits made by me (jacquelinekclee) are denoted in the docstrings.</li>
</ul>
<h2 id="legality">Legality</h2>
<p>This personal project was made for the sole intent of applying my skills in Python thus far and as a way to learn new ones. It is intended for non-commercial uses only.</p>
<p>Some issues with webscraping from AZLyrics arose as I was developing this project because the website detected an unusual amount of activity. An alternative to AZLyrics is
<a href="https://archive.org/">archive.org</a>, a website that regularly stores archives for various webpages. Nonetheless, using the <a href="https://nbviewer.jupyter.org/github/jacquelinekclee/hiphop_nlp_webscrape/blob/master/Has%20Hip-Hop%20Gotten%20Worse_.ipynb">Jupyter Notebook viewer</a> should not present any issues.</p>
</li>
</ul>
<p><a href="#table-of-contents">(Back to top)</a></p>

					</article>

					

					<article id = "hiphop">
						<h1 id="has-hip-hop-gotten-worse-web-scraping-and-nlp-project">Has Hip-Hop Gotten Worse? - Web Scraping and NLP Project</h1>
<p><img src="/docs/assets/rappers.JPG" alt="banner"></p>
<p><a href="https://www.behance.net/gallery/32828663/Complex-Best-Rapper-Alive-since-1979">SOURCE</a></p>
<h1 id="links">Links</h1>
<ul>
<li><a href="https://jacquelinekclee.github.io/hiphop_nlp_webscrape/">Website</a></li>
<li><a href="https://github.com/jacquelinekclee/hiphop_nlp_webscrape/">Repository (with all relevant files/data)</a></li>
</ul>
<h1 id="table-of-contents">Table of contents</h1>
<ul>
<li><a href="#background">Background</a></li>
<li><a href="#song-selection">Song Selection</a></li>
<li><a href="#lyrics-source">Lyrics Source</a></li>
<li><a href="#metrics">Metrics</a></li>
<li><a href="#goal">Goal</a></li>
<li><a href="#usage">Usage</a></li>
<li><a href="#findings">Findings</a></li>
<li><a href="#legality">Legality</a></li>
<li><a href="#source-files">Source Files</a></li>
</ul>
<h2 id="background">Background</h2>
<p>Hip-hop/rap music was founded in the 1970&#39;s and became widespread during the 80&#39;s, kicking off the decade-long era known as the &quot;golden age&quot; of hip-hop <a href="https://www.npr.org/templates/story/story.php?storyId=7550286#:~:text=Rap%20as%20a%20genre%20began,generally%20interacting%20with%20the%20audience.">(NPR)</a>.</p>
<p>Today, hip-hop/rap is music&#39;s most popular and commercially successful genre. Every region has its own style of rap and numerous musical and cultural trends have defined hip-hop over the years.</p>
<p>Many fans believe that rap music has gotten worse over the years, crediting this decline to the rise of what is called <a href="https://www.cleveland.com/entertainment/2017/06/what_is_mumble_rap_25_essentia.html">mumble rap</a>, a style characterized by artists rapping inchorently and/or melodically and using a variety of ad-libs as opposed to actual lyrics. But, while mumble rap has certainly risen in popularity, does this mean that &quot;good&quot; rap, music filled with clever and meaningful lyrics, has vanished from the genre? </p>
<p>To answer this question, I will be analyzing the lyrics of the best rap song from every year from 1990 to 2020. </p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="song-selection">Song Selection</h2>
<p>Songs from 1990-2003 will be pulled from <strong>Complex article, <a href="https://www.complex.com/music/best-rap-songs-since-1979/">&quot;The Best Rap Song, Every Year Since 1979&quot;</a></strong> and the songs from 2004-2020 will be the winners of the <strong><a href="https://en.wikipedia.org/wiki/Grammy_Award_for_Best_Rap_Song#Recipients">Grammy Award for Best Rap Song</a></strong> (first awarded in 2004).</p>
<ul>
<li>Since many artists have won the Best Rap Song award multiple times (Kanye West, JAY-Z, Kendrick Lamar), this analysis focuses more on whether or not the best of the best rap songs from more current years are just as good as those from the 90&#39;s and early 2000&#39;s rather than finding out if the hip-hop/rap genre as a whole has seen a decline in song quality.</li>
<li>&quot;The Choice Is Yours&quot; by Black Sheep is not on AZLyrics and also not on Spotify, so I will use one of Complex&#39;s honorable mentions, &quot;My Mind Playin&#39; Tricks On Me&quot; by Geto Boys.</li>
<li>Complex&#39;s choice for 2002 (&quot;Lose Yourself&quot; by Eminem) is the same as the 2004 Best Rap Song recipient, so similarly I will use one of Complex&#39;s honorable mentions, &quot;Grindin&quot; by The Clipse.</li>
</ul>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="lyrics-source">Lyrics Source</h2>
<p>The lyrics for each will be scraped from <strong><a href="https://www.azlyrics.com/">AZLyrics</a></strong>. Since these lyrics are user submitted, the formatting of lyrics is variable. This variation is largely in how chorus lyrics are posted. For example, one song may have all the lyrics to the entire chorus typed out each time whereas another may just use &#39;[Chorus]&#39; or &#39;[2x]&#39; to avoid repetition. My hope is that this will not affect the metrics too much, as songs with shorter/less repetitive choruses can indicate a song&#39;s greater substance and lyrical quality.</p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="metrics-">Metrics:</h2>
<ul>
<li>Proportion of unique words to total words, excluding stop words.<ul>
<li>Evaluates the range of vocabulary in a given song.</li>
</ul>
</li>
<li>Proportion of stop words to total words.<ul>
<li>Indicates the substance of a song&#39;s lyrics.</li>
</ul>
</li>
<li>Average number of syllables per bar.<ul>
<li>Examines a rapper&#39;s skill, as it takes more creativity and ingenuity to fit a greater number of syllables into a bar.</li>
</ul>
</li>
<li>Proportion of exact end rhymes and vowel end rhymes (in every two bars or every other bar) to number of bars.<ul>
<li>Also examines a rapper&#39;s lyricism.</li>
<li>Most common rhyme schemes are aabb and abab, so I will only look for these 2.</li>
<li>I will exclude bars using the same words to create the rhyme scheme. In other words, if two bars are &quot;I like greens / She likes greens,&quot; this rhyme will not be counted as the same word is used. This will be done in attempt to accredit songs that more cleverly create rhyme schemes and to avoid inflating this metric for songs with choruses that may be extremely repetitive (e.g., <a href="https://www.azlyrics.com/lyrics/llcoolj/mamasaidknockyouout.html">&quot;Mama Said Knock You Out&quot; by LL Cool J</a>).</li>
<li>The fucntions used to analyze rhymes use the Carnegie Mellon University Pronouncing Dictionary. Therefore, the creativity and accents rapper use to manipulate different rhymes will unfortunately not be detected. Thus, this measure will be analyzed with a grain of salt.</li>
</ul>
</li>
<li>Additionally, I will also be looking at the most common words (excluding stop words) for each song. This measure is much more subjective than the others, but could potentially give insight into a song&#39;s substance.</li>
</ul>
<p><a href="#table-of-contents">(Back to top)</a></p>
<p>Here are some quick definitions of terms used in this project:</p>
<ul>
<li><strong><a href="https://www.lexico.com/en/definition/bar">Bar</a></strong>: One line of lyrics. Detected by line break characters. Typically takes four beats.</li>
<li><strong><a href="https://literarydevices.net/end-rhyme/">End rhymes</a></strong>: Rhymes that occur with the last word/syllables of a bar. Example: &quot;I like greens / She likes beans&quot; (greens and beans, the last word of each bar/line, rhyme).</li>
<li><strong><a href="https://literarydevices.net/exact-rhyme/">Exact rhyme</a></strong>: When the vowel sound and final consonant of two words are phonetically the same, e.g. greens and beans.</li>
<li><strong><a href="https://www.thefreedictionary.com/vowel+rhyme">Vowel rhyme</a></strong>: When the vowel sound of two words are phonetically the same, e.g. green and seem.</li>
<li><strong><a href="https://www.geeksforgeeks.org/removing-stop-words-nltk-python">Stop word</a></strong>: A word that does not contribute much meaning, e.g. the, a, an. Search engines are programmed to ignore these words, and ignoring these words both save processing time and allow us to analyze lyrics more meaningfully.</li>
</ul>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="goal">Goal</h2>
<p>As stated above, this project has some limitations in terms of the consistency of lyric data, the extent to which the packages/tools used can analyze rap lyrics, and the overall subjectivity of this topic. Ultimately, I started this project as a fun way to both explore one of my interests and utilize the skills and technical knowledge I have learned thus far. But, I certainly believe that the results of this project can give insight into how rap music has evolved over the years.</p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="usage">Usage</h2>
<p>Please refer to the <a href="https://nbviewer.jupyter.org/github/jacquelinekclee/hiphop_nlp_webscrape/blob/master/Has%20Hip-Hop%20Gotten%20Worse_.ipynb">Jupyter Notebook viewer</a> to view all the code and visualizations created during this project.</p>
<p>The <a href="#source-files">source files</a> contain all the functions used to web scrape, process the text, and calcualte the metrics used for the project.</p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="findings">Findings</h2>
<p>While all four metrics seemed to decline over the years, <strong>% Unique Rhymes to All Rhymes</strong> (number of unique rhymes / number of all rhymes) proved to be the metric with:</p>
<ul>
<li>The strongest correlation coefficient (-0.52)</li>
<li>Lowest p-value (p = 0.003)</li>
</ul>
<p><img src="/docs/assets/rhymes_plot.png" alt="scatter"></p>
<p>Even though what qualifies as &quot;good music&quot; will always be subjective, quantifying the quality of lyrics in these songs proved to be insightful. The generally weak relationships between each metric and year indicate that any &quot;decline&quot; in hip-hop/rap music may not be as strong as some would assume. </p>
<p>As mentioned above, hip-hop has become the most popular genre of music. With this ever increasing popularity comes more commercial and lucrative opportunities, and such opportunities are not necessarily conducive to lyrically complex and intricately crafted songs. The genre becoming more commerical and marketable does not mean that there are no lyrically interesting songs being made. But, this trend may contribute to an oversaturated market, where mostly catchy, less intricate songs become popular.</p>
<p>Overall, this project gives evidence that hip-hop as a genre has not seen a dramatic decline. Instead, changing trends in the music industry and how the public consumes media may affect what types of songs become most popular, but not necessarily the skills of all rappers.  </p>
<p><a href="#table-of-contents">(Back to top)</a></p>
<h2 id="source-files">Source Files</h2>
<ul>
<li><a href="https://github.com/jacquelinekclee/hiphop_nlp_webscrape/blob/master/web_scrape.py">web_scrape.py</a><ul>
<li>Has all the functions used for web scraping and processing the HTML. It also processes the string (lyrics) so it&#39;s ready for analyzing the lyrics.</li>
</ul>
</li>
<li><a href="https://github.com/jacquelinekclee/hiphop_nlp_webscrape/blob/master/lyrics.py">lyrics.py</a><ul>
<li>Used to break down the string of lyrics into bars and words and calculate the word based metrics.</li>
</ul>
</li>
<li><p><a href="https://github.com/jacquelinekclee/hiphop_nlp_webscrape/blob/master/rhyme.py">rhyme.py</a></p>
<ul>
<li>Provides the functions used to calculate the rhyme-based metrics</li>
<li>The contents of this file are adopted from the dandelion package as laid out <a href="https://github.com/DiegoVicen/dandelion">here</a>. Edits made by me (jacquelinekclee) are denoted in the docstrings.</li>
</ul>
<h2 id="legality">Legality</h2>
<p>This personal project was made for the sole intent of applying my skills in Python thus far and as a way to learn new ones. It is intended for non-commercial uses only.</p>
<p>Some issues with webscraping from AZLyrics arose as I was developing this project because the website detected an unusual amount of activity. An alternative to AZLyrics is
<a href="https://archive.org/">archive.org</a>, a website that regularly stores archives for various webpages. Nonetheless, using the <a href="https://nbviewer.jupyter.org/github/jacquelinekclee/hiphop_nlp_webscrape/blob/master/Has%20Hip-Hop%20Gotten%20Worse_.ipynb">Jupyter Notebook viewer</a> should not present any issues.</p>
</li>
</ul>
<p><a href="#table-of-contents">(Back to top)</a></p>

					</article>

				</div>

					

				<!-- Footer -->
					<footer id="footer">
						<p class="copyright">&copy; Jacqueline Lee. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
					</footer>

			</div>

		<!-- BG -->
			<div id="bg"></div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
